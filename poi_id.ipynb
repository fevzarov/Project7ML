{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enron Fraud Case: Identifying Person of Interest (POI) using Machine Learning Tools\n",
    "\n",
    "For this project, we utilize machine learning skills to choose a algorithm to identify Enron Employees who may have committed fraud based on the public Enron financial and email datasets. The approach to arrive at a best model include:\n",
    "\n",
    "* handling real-world dataset: Since such dataset tends to be imperfect, we may have to clean and remove the data plus make some assumptions about the data inadequacies; \n",
    "* validating machine learning results using test data;\n",
    "* evaluate machine learning result using quantitative metrics such as accuracy, precision, and recall scores;\n",
    "* dealing with features: This includes creating, selecting, and transforming variables;\n",
    "* comparing the performance of various machine learning algorithms\n",
    "* fine tuning machine learning algorithms for maximum performance; and\n",
    "* communicating your machine learning algorithm results clearly.\n",
    "\n",
    "At the minimum, the best machine learning algorithm chose will have precision and recall scores of at least 0.3.\n",
    "\n",
    "\n",
    "###### Project Overview\n",
    "\n",
    "In 2000, Enron was one of the largest companies in the United States. By 2002, it had collapsed into bankruptcy due to widespread corporate fraud due to misleading accounting practices. In the resulting Federal investigation, a significant amount of typically confidential information entered into the public record, including tens of thousands of emails and detailed financial data for top executives. \n",
    "\n",
    "Using Machine Learning tools, we built a best model for a person of interest identifier based on financial and email data made public as a result of the Enron scandal. The dataset provided by Udacity has the persons of interest in the fraud case tagged, which is defined by individuals who were indicted, reached a settlement or plea deal with the government, or testified in exchange for prosecution immunity.\n",
    "\n",
    "##### Analyses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Base Packages & Path\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot\n",
    "import tester\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tester import test_classifier\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Task 1: Select what features you'll use__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 1: Select what features you'll use. ###\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "### features_list = ['poi','salary'] # You will need to use more features\n",
    "# data_label = 'poi'\n",
    "# features_list = enron_tools.get_features(data_dict)\n",
    "\n",
    "# features_list = ['poi','salary', 'expenses', 'total_stock_value', 'bonus', 'from_poi_to_this_person', 'shared_receipt_with_poi'] # You will need to use more features\n",
    "\n",
    "features_financial = ['salary', 'deferral_payments', 'total_payments',\n",
    "                      'loan_advances', 'bonus', 'restricted_stock_deferred', \n",
    "                      'deferred_income', 'total_stock_value', 'expenses', \n",
    "                      'exercised_stock_options', 'other', \n",
    "                      'long_term_incentive', 'restricted_stock', \n",
    "                      'director_fees']\n",
    "                      \n",
    "features_email = ['to_messages', 'email_address', 'from_poi_to_this_person', \n",
    "                  'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi']\n",
    "\n",
    "# Removing email address - not likely to be useful\n",
    "# due to missing emails, already have name, and categorical nature.\n",
    "features_email.remove('email_address')\n",
    "\n",
    "# Initial Fueature List for Analysis\n",
    "features_list = ['poi'] + features_financial + features_email\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data Overview\n",
    "\n",
    "*Important Dataset Characteristics*\n",
    "\n",
    "The original data contains 146 observations with 21 features. Of these 146 observations, 128 observations were persons of interests (POI). With no missing value, 18 observations were non-POIs.\n",
    "\n",
    "For our Machine Learning analyses, we focussed on three features: exercised_stock_options, bonus, and salary. We could have gone with more but we found out that additional features did not add much to the model, in terms of model performance. \n",
    "\n",
    "\"NaN\" issue is an issue in this dataset. Only 4 features have values for more than 75% of observations. Six of them have less than 50% missing values, i.e. loan_advances, director_fees, restricted_stock_deferred, deferral_payments, deferred_income, and long_term_incentive. For this project, we assumed these \"NaN\" values to be zero for simplicity. \n",
    "\n",
    "*Missing Values*\n",
    "\n",
    "In research, missing values may not be the first thing we look into. After conducting a few analyses with the data, I noticed that the significant numbers of \"NaN\" values may pose a problem for the analysis. \n",
    "\n",
    "In this Machine Learning course, we did not go through the algorithm on how we arrived at the best fitting algorithm. However, based on what I know about regression, \"NaN\" or too many zero values would not be the most useful in arriving at a fitting model. So, my hypothesis is that variables with many NaN values would not be useful for precision and recall. Hopefully, *SelectKBest* will tell us if this is true. Besides *SelectKBest*, we need to be cognizant of not including variables that tend to be highly correlated - either via definition or correlation finding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_advances                  4\n",
       "director_fees                 17\n",
       "restricted_stock_deferred     18\n",
       "deferral_payments             39\n",
       "deferred_income               49\n",
       "long_term_incentive           66\n",
       "bonus                         82\n",
       "from_poi_to_this_person       86\n",
       "to_messages                   86\n",
       "shared_receipt_with_poi       86\n",
       "from_this_person_to_poi       86\n",
       "from_messages                 86\n",
       "other                         93\n",
       "salary                        95\n",
       "expenses                      95\n",
       "exercised_stock_options      102\n",
       "restricted_stock             110\n",
       "email_address                111\n",
       "total_payments               125\n",
       "total_stock_value            126\n",
       "poi                          146\n",
       "dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Missing Value count helps to determine less useful variables\n",
    "# Dataframe Table Format\n",
    "\n",
    "enron_df = pd.DataFrame.from_dict(data_dict, orient = \"index\")\n",
    "enron_df.replace(to_replace='NaN', value=np.nan, inplace=True)\n",
    "\n",
    "enron_df.count().sort_values()\n",
    "\n",
    "# Missing data is an issue if we want to use the data for analyses\n",
    "# Are these NaNs missing values or non-inputted values, thus, they should be zero?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features are sorted by the number of valid response with the least numberof valied response listed the first. A question we need to address here is whether the \"not a number\" response here are actually zero or missing values. This is actually a huge portion of a project in real life, especially for a case of this magnitude. This approach is time consuming because we extensive research requirement. A simpler approach would be to impute these zero-or-missing values but things can easily get messy here too. Imputations introduce errors to the data if not performed well. For this study, we assume that these values are actually **zeroes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataframe Table Format\n",
    "enron_df = pd.DataFrame.from_dict(data_dict, orient = \"index\")\n",
    "\n",
    "# Setting index name of pandas data frame to POI's name\n",
    "enron_df.index.name = \"Name\"\n",
    "\n",
    "# Removing Less Useful Column - Already Have Unique Name\n",
    "enron_df.drop([\"email_address\"], inplace=True,axis=1)\n",
    "\n",
    "#convert columns from objects to float\n",
    "for c in enron_df.columns:\n",
    "    if enron_df[c].dtype == object:\n",
    "        enron_df[c] = enron_df[c].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which observations have the many missing values?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    146.000000\n",
      "mean       9.061644\n",
      "std        4.296306\n",
      "min        2.000000\n",
      "25%        5.000000\n",
      "50%        9.000000\n",
      "75%       12.000000\n",
      "max       19.000000\n",
      "Name: nmiss, dtype: float64\n",
      "Median= 9.0\n"
     ]
    }
   ],
   "source": [
    "### Missing Variables\n",
    "enron_df[\"nmiss\"] = enron_df.isnull().sum(axis = 1)\n",
    "print(enron_df[\"nmiss\"].describe())\n",
    "print \"Median=\", (enron_df[\"nmiss\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>nmiss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CHRISTODOULOU DIOMEDES</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5127155.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>950730.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6077885.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLINE KENNETH W</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>662086.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-472568.0</td>\n",
       "      <td>189518.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GILLIS JOHN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9803.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75838.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85641.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRAMM WENDY L</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119292.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>119292.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOCKHART EUGENE E</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAVAGE FRANK</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>125034.0</td>\n",
       "      <td>-121284.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCRIMSHAW MATTHEW</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>759557.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>759557.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THE TRAVEL AGENCY IN THE PARK</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>362096.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>362096.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAKEHAM JOHN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>213071.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>109298.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHALEY DAVID A</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98718.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98718.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WODRASKA JOHN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189583.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189583.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WROBEL BRUCE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               salary  to_messages  deferral_payments  \\\n",
       "Name                                                                    \n",
       "CHRISTODOULOU DIOMEDES            NaN          NaN                NaN   \n",
       "CLINE KENNETH W                   NaN          NaN                NaN   \n",
       "GILLIS JOHN                       NaN          NaN                NaN   \n",
       "GRAMM WENDY L                     NaN          NaN                NaN   \n",
       "LOCKHART EUGENE E                 NaN          NaN                NaN   \n",
       "SAVAGE FRANK                      NaN          NaN                NaN   \n",
       "SCRIMSHAW MATTHEW                 NaN          NaN                NaN   \n",
       "THE TRAVEL AGENCY IN THE PARK     NaN          NaN                NaN   \n",
       "WAKEHAM JOHN                      NaN          NaN                NaN   \n",
       "WHALEY DAVID A                    NaN          NaN                NaN   \n",
       "WODRASKA JOHN                     NaN          NaN                NaN   \n",
       "WROBEL BRUCE                      NaN          NaN                NaN   \n",
       "\n",
       "                               total_payments  exercised_stock_options  bonus  \\\n",
       "Name                                                                            \n",
       "CHRISTODOULOU DIOMEDES                    NaN                5127155.0    NaN   \n",
       "CLINE KENNETH W                           NaN                      NaN    NaN   \n",
       "GILLIS JOHN                               NaN                   9803.0    NaN   \n",
       "GRAMM WENDY L                        119292.0                      NaN    NaN   \n",
       "LOCKHART EUGENE E                         NaN                      NaN    NaN   \n",
       "SAVAGE FRANK                           3750.0                      NaN    NaN   \n",
       "SCRIMSHAW MATTHEW                         NaN                 759557.0    NaN   \n",
       "THE TRAVEL AGENCY IN THE PARK        362096.0                      NaN    NaN   \n",
       "WAKEHAM JOHN                         213071.0                      NaN    NaN   \n",
       "WHALEY DAVID A                            NaN                  98718.0    NaN   \n",
       "WODRASKA JOHN                        189583.0                      NaN    NaN   \n",
       "WROBEL BRUCE                              NaN                 139130.0    NaN   \n",
       "\n",
       "                               restricted_stock  shared_receipt_with_poi  \\\n",
       "Name                                                                       \n",
       "CHRISTODOULOU DIOMEDES                 950730.0                      NaN   \n",
       "CLINE KENNETH W                        662086.0                      NaN   \n",
       "GILLIS JOHN                             75838.0                      NaN   \n",
       "GRAMM WENDY L                               NaN                      NaN   \n",
       "LOCKHART EUGENE E                           NaN                      NaN   \n",
       "SAVAGE FRANK                                NaN                      NaN   \n",
       "SCRIMSHAW MATTHEW                           NaN                      NaN   \n",
       "THE TRAVEL AGENCY IN THE PARK               NaN                      NaN   \n",
       "WAKEHAM JOHN                                NaN                      NaN   \n",
       "WHALEY DAVID A                              NaN                      NaN   \n",
       "WODRASKA JOHN                               NaN                      NaN   \n",
       "WROBEL BRUCE                                NaN                      NaN   \n",
       "\n",
       "                               restricted_stock_deferred  total_stock_value  \\\n",
       "Name                                                                          \n",
       "CHRISTODOULOU DIOMEDES                               NaN          6077885.0   \n",
       "CLINE KENNETH W                                -472568.0           189518.0   \n",
       "GILLIS JOHN                                          NaN            85641.0   \n",
       "GRAMM WENDY L                                        NaN                NaN   \n",
       "LOCKHART EUGENE E                                    NaN                NaN   \n",
       "SAVAGE FRANK                                         NaN                NaN   \n",
       "SCRIMSHAW MATTHEW                                    NaN           759557.0   \n",
       "THE TRAVEL AGENCY IN THE PARK                        NaN                NaN   \n",
       "WAKEHAM JOHN                                         NaN                NaN   \n",
       "WHALEY DAVID A                                       NaN            98718.0   \n",
       "WODRASKA JOHN                                        NaN                NaN   \n",
       "WROBEL BRUCE                                         NaN           139130.0   \n",
       "\n",
       "                               ...    loan_advances  from_messages     other  \\\n",
       "Name                           ...                                             \n",
       "CHRISTODOULOU DIOMEDES         ...              NaN            NaN       NaN   \n",
       "CLINE KENNETH W                ...              NaN            NaN       NaN   \n",
       "GILLIS JOHN                    ...              NaN            NaN       NaN   \n",
       "GRAMM WENDY L                  ...              NaN            NaN       NaN   \n",
       "LOCKHART EUGENE E              ...              NaN            NaN       NaN   \n",
       "SAVAGE FRANK                   ...              NaN            NaN       NaN   \n",
       "SCRIMSHAW MATTHEW              ...              NaN            NaN       NaN   \n",
       "THE TRAVEL AGENCY IN THE PARK  ...              NaN            NaN  362096.0   \n",
       "WAKEHAM JOHN                   ...              NaN            NaN       NaN   \n",
       "WHALEY DAVID A                 ...              NaN            NaN       NaN   \n",
       "WODRASKA JOHN                  ...              NaN            NaN  189583.0   \n",
       "WROBEL BRUCE                   ...              NaN            NaN       NaN   \n",
       "\n",
       "                               from_this_person_to_poi    poi  director_fees  \\\n",
       "Name                                                                           \n",
       "CHRISTODOULOU DIOMEDES                             NaN  False            NaN   \n",
       "CLINE KENNETH W                                    NaN  False            NaN   \n",
       "GILLIS JOHN                                        NaN  False            NaN   \n",
       "GRAMM WENDY L                                      NaN  False       119292.0   \n",
       "LOCKHART EUGENE E                                  NaN  False            NaN   \n",
       "SAVAGE FRANK                                       NaN  False       125034.0   \n",
       "SCRIMSHAW MATTHEW                                  NaN  False            NaN   \n",
       "THE TRAVEL AGENCY IN THE PARK                      NaN  False            NaN   \n",
       "WAKEHAM JOHN                                       NaN  False       109298.0   \n",
       "WHALEY DAVID A                                     NaN  False            NaN   \n",
       "WODRASKA JOHN                                      NaN  False            NaN   \n",
       "WROBEL BRUCE                                       NaN  False            NaN   \n",
       "\n",
       "                               deferred_income  long_term_incentive  \\\n",
       "Name                                                                  \n",
       "CHRISTODOULOU DIOMEDES                     NaN                  NaN   \n",
       "CLINE KENNETH W                            NaN                  NaN   \n",
       "GILLIS JOHN                                NaN                  NaN   \n",
       "GRAMM WENDY L                              NaN                  NaN   \n",
       "LOCKHART EUGENE E                          NaN                  NaN   \n",
       "SAVAGE FRANK                         -121284.0                  NaN   \n",
       "SCRIMSHAW MATTHEW                          NaN                  NaN   \n",
       "THE TRAVEL AGENCY IN THE PARK              NaN                  NaN   \n",
       "WAKEHAM JOHN                               NaN                  NaN   \n",
       "WHALEY DAVID A                             NaN                  NaN   \n",
       "WODRASKA JOHN                              NaN                  NaN   \n",
       "WROBEL BRUCE                               NaN                  NaN   \n",
       "\n",
       "                               from_poi_to_this_person  nmiss  \n",
       "Name                                                           \n",
       "CHRISTODOULOU DIOMEDES                             NaN     16  \n",
       "CLINE KENNETH W                                    NaN     16  \n",
       "GILLIS JOHN                                        NaN     16  \n",
       "GRAMM WENDY L                                      NaN     17  \n",
       "LOCKHART EUGENE E                                  NaN     19  \n",
       "SAVAGE FRANK                                       NaN     16  \n",
       "SCRIMSHAW MATTHEW                                  NaN     17  \n",
       "THE TRAVEL AGENCY IN THE PARK                      NaN     17  \n",
       "WAKEHAM JOHN                                       NaN     16  \n",
       "WHALEY DAVID A                                     NaN     17  \n",
       "WODRASKA JOHN                                      NaN     17  \n",
       "WROBEL BRUCE                                       NaN     17  \n",
       "\n",
       "[12 rows x 21 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's Analyze Observation with so Many Missing Data\n",
    "enron_df[enron_df[\"nmiss\"]>15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have one person with no meaningful data, so, we'll expunge **\"LOCKHART EUGENE E\"** from the dataset. I contemplated on removing the other observations with too many \"NaN\" values. \n",
    "\n",
    "I noticed that all of these individuals have NaN (zero?) income. They either had either  stocks or received director fees. Both of them may be useful in poi algorithm. So, we've decided to keep these observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  count\n",
       "poi         \n",
       "False    128\n",
       "True      18"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_count = pd.crosstab(index = enron_df[\"poi\"],columns=\"count\") \n",
    "poi_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Dimension: (146, 21)\n",
      "Original Dataset Observations: 146\n",
      "Original Dataset Variables: 21\n",
      "\n",
      "UNIVARIATE STATISTICS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>95.0</td>\n",
       "      <td>5.621943e+05</td>\n",
       "      <td>2.716369e+06</td>\n",
       "      <td>477.0</td>\n",
       "      <td>211816.00</td>\n",
       "      <td>259996.0</td>\n",
       "      <td>312117.00</td>\n",
       "      <td>26704229.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_messages</th>\n",
       "      <td>86.0</td>\n",
       "      <td>2.073860e+03</td>\n",
       "      <td>2.582701e+03</td>\n",
       "      <td>57.0</td>\n",
       "      <td>541.25</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>2634.75</td>\n",
       "      <td>15149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferral_payments</th>\n",
       "      <td>39.0</td>\n",
       "      <td>1.642674e+06</td>\n",
       "      <td>5.161930e+06</td>\n",
       "      <td>-102500.0</td>\n",
       "      <td>81573.00</td>\n",
       "      <td>227449.0</td>\n",
       "      <td>1002671.50</td>\n",
       "      <td>32083396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_payments</th>\n",
       "      <td>125.0</td>\n",
       "      <td>5.081526e+06</td>\n",
       "      <td>2.906172e+07</td>\n",
       "      <td>148.0</td>\n",
       "      <td>394475.00</td>\n",
       "      <td>1101393.0</td>\n",
       "      <td>2093263.00</td>\n",
       "      <td>309886585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <td>102.0</td>\n",
       "      <td>5.987054e+06</td>\n",
       "      <td>3.106201e+07</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>527886.25</td>\n",
       "      <td>1310813.5</td>\n",
       "      <td>2547724.00</td>\n",
       "      <td>311764000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>82.0</td>\n",
       "      <td>2.374235e+06</td>\n",
       "      <td>1.071333e+07</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>431250.00</td>\n",
       "      <td>769375.0</td>\n",
       "      <td>1200000.00</td>\n",
       "      <td>97343619.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock</th>\n",
       "      <td>110.0</td>\n",
       "      <td>2.321741e+06</td>\n",
       "      <td>1.251828e+07</td>\n",
       "      <td>-2604490.0</td>\n",
       "      <td>254018.00</td>\n",
       "      <td>451740.0</td>\n",
       "      <td>1002369.75</td>\n",
       "      <td>130322299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <td>86.0</td>\n",
       "      <td>1.176465e+03</td>\n",
       "      <td>1.178318e+03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>249.75</td>\n",
       "      <td>740.5</td>\n",
       "      <td>1888.25</td>\n",
       "      <td>5521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.664106e+05</td>\n",
       "      <td>4.201494e+06</td>\n",
       "      <td>-7576788.0</td>\n",
       "      <td>-389621.75</td>\n",
       "      <td>-146975.0</td>\n",
       "      <td>-75009.75</td>\n",
       "      <td>15456290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_stock_value</th>\n",
       "      <td>126.0</td>\n",
       "      <td>6.773957e+06</td>\n",
       "      <td>3.895777e+07</td>\n",
       "      <td>-44093.0</td>\n",
       "      <td>494510.25</td>\n",
       "      <td>1102872.5</td>\n",
       "      <td>2949846.75</td>\n",
       "      <td>434509511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expenses</th>\n",
       "      <td>95.0</td>\n",
       "      <td>1.087289e+05</td>\n",
       "      <td>5.335348e+05</td>\n",
       "      <td>148.0</td>\n",
       "      <td>22614.00</td>\n",
       "      <td>46950.0</td>\n",
       "      <td>79952.50</td>\n",
       "      <td>5235198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_advances</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.196250e+07</td>\n",
       "      <td>4.708321e+07</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>1600000.00</td>\n",
       "      <td>41762500.0</td>\n",
       "      <td>82125000.00</td>\n",
       "      <td>83925000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_messages</th>\n",
       "      <td>86.0</td>\n",
       "      <td>6.087907e+02</td>\n",
       "      <td>1.841034e+03</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.75</td>\n",
       "      <td>41.0</td>\n",
       "      <td>145.50</td>\n",
       "      <td>14368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>93.0</td>\n",
       "      <td>9.190650e+05</td>\n",
       "      <td>4.589253e+06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1215.00</td>\n",
       "      <td>52382.0</td>\n",
       "      <td>362096.00</td>\n",
       "      <td>42667589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <td>86.0</td>\n",
       "      <td>4.123256e+01</td>\n",
       "      <td>1.000731e+02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.75</td>\n",
       "      <td>609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director_fees</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.668049e+05</td>\n",
       "      <td>3.198914e+05</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>98784.00</td>\n",
       "      <td>108579.0</td>\n",
       "      <td>113784.00</td>\n",
       "      <td>1398517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferred_income</th>\n",
       "      <td>49.0</td>\n",
       "      <td>-1.140475e+06</td>\n",
       "      <td>4.025406e+06</td>\n",
       "      <td>-27992891.0</td>\n",
       "      <td>-694862.00</td>\n",
       "      <td>-159792.0</td>\n",
       "      <td>-38346.00</td>\n",
       "      <td>-833.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_term_incentive</th>\n",
       "      <td>66.0</td>\n",
       "      <td>1.470361e+06</td>\n",
       "      <td>5.942759e+06</td>\n",
       "      <td>69223.0</td>\n",
       "      <td>281250.00</td>\n",
       "      <td>442035.0</td>\n",
       "      <td>938672.00</td>\n",
       "      <td>48521928.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <td>86.0</td>\n",
       "      <td>6.489535e+01</td>\n",
       "      <td>8.697924e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>72.25</td>\n",
       "      <td>528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nmiss</th>\n",
       "      <td>146.0</td>\n",
       "      <td>9.061644e+00</td>\n",
       "      <td>4.296306e+00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count          mean           std         min  \\\n",
       "salary                      95.0  5.621943e+05  2.716369e+06       477.0   \n",
       "to_messages                 86.0  2.073860e+03  2.582701e+03        57.0   \n",
       "deferral_payments           39.0  1.642674e+06  5.161930e+06   -102500.0   \n",
       "total_payments             125.0  5.081526e+06  2.906172e+07       148.0   \n",
       "exercised_stock_options    102.0  5.987054e+06  3.106201e+07      3285.0   \n",
       "bonus                       82.0  2.374235e+06  1.071333e+07     70000.0   \n",
       "restricted_stock           110.0  2.321741e+06  1.251828e+07  -2604490.0   \n",
       "shared_receipt_with_poi     86.0  1.176465e+03  1.178318e+03         2.0   \n",
       "restricted_stock_deferred   18.0  1.664106e+05  4.201494e+06  -7576788.0   \n",
       "total_stock_value          126.0  6.773957e+06  3.895777e+07    -44093.0   \n",
       "expenses                    95.0  1.087289e+05  5.335348e+05       148.0   \n",
       "loan_advances                4.0  4.196250e+07  4.708321e+07    400000.0   \n",
       "from_messages               86.0  6.087907e+02  1.841034e+03        12.0   \n",
       "other                       93.0  9.190650e+05  4.589253e+06         2.0   \n",
       "from_this_person_to_poi     86.0  4.123256e+01  1.000731e+02         0.0   \n",
       "director_fees               17.0  1.668049e+05  3.198914e+05      3285.0   \n",
       "deferred_income             49.0 -1.140475e+06  4.025406e+06 -27992891.0   \n",
       "long_term_incentive         66.0  1.470361e+06  5.942759e+06     69223.0   \n",
       "from_poi_to_this_person     86.0  6.489535e+01  8.697924e+01         0.0   \n",
       "nmiss                      146.0  9.061644e+00  4.296306e+00         2.0   \n",
       "\n",
       "                                  25%         50%          75%          max  \n",
       "salary                      211816.00    259996.0    312117.00   26704229.0  \n",
       "to_messages                    541.25      1211.0      2634.75      15149.0  \n",
       "deferral_payments            81573.00    227449.0   1002671.50   32083396.0  \n",
       "total_payments              394475.00   1101393.0   2093263.00  309886585.0  \n",
       "exercised_stock_options     527886.25   1310813.5   2547724.00  311764000.0  \n",
       "bonus                       431250.00    769375.0   1200000.00   97343619.0  \n",
       "restricted_stock            254018.00    451740.0   1002369.75  130322299.0  \n",
       "shared_receipt_with_poi        249.75       740.5      1888.25       5521.0  \n",
       "restricted_stock_deferred  -389621.75   -146975.0    -75009.75   15456290.0  \n",
       "total_stock_value           494510.25   1102872.5   2949846.75  434509511.0  \n",
       "expenses                     22614.00     46950.0     79952.50    5235198.0  \n",
       "loan_advances              1600000.00  41762500.0  82125000.00   83925000.0  \n",
       "from_messages                   22.75        41.0       145.50      14368.0  \n",
       "other                         1215.00     52382.0    362096.00   42667589.0  \n",
       "from_this_person_to_poi          1.00         8.0        24.75        609.0  \n",
       "director_fees                98784.00    108579.0    113784.00    1398517.0  \n",
       "deferred_income            -694862.00   -159792.0    -38346.00       -833.0  \n",
       "long_term_incentive         281250.00    442035.0    938672.00   48521928.0  \n",
       "from_poi_to_this_person         10.00        35.0        72.25        528.0  \n",
       "nmiss                            5.00         9.0        12.00         19.0  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Since describe produces freq and top=NaN, \n",
    "### convert 'NaN' from strings to a real 'NaN'\n",
    "enron_df.replace(to_replace='NaN', value=np.nan, inplace=True)\n",
    "\n",
    "data_point_orig = enron_df.shape[0]\n",
    "\n",
    "print \"Original Dataset Dimension:\",enron_df.shape\n",
    "print \"Original Dataset Observations:\",enron_df.shape[0]\n",
    "print \"Original Dataset Variables:\",enron_df.shape[1]\n",
    "\n",
    "print \"\\nUNIVARIATE STATISTICS\"\n",
    "enron_df.describe().transpose()\n",
    "# enron_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Univariate statistical analyses may tell us about bad data too. For example, we look into the data range. Data points thta fall outside an expected range shoudld be investigated. An obvious example is salary, which should be positive. \n",
    "\n",
    "My three immediate concerns pertain to *restricted stocks*, *restricted stock deferred*, and *total stocks* because these financial assets can take negative and positive values. Based on my limited knowledge on corporate finance, I can see how specific stocks may have negative values. People may have purchased stocks when their values were really high and sold them when their values were low - most likely at the *peak* of the scandal. In the end, I take all these values as accpetable and they are included in the analyses.\n",
    "\n",
    "##### Other Data Explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Typical Data Checks\n",
    "# print \"Dataframe dimension is\", enron_df.shape\n",
    "# print \"\\nName is the Index: \\n\",enron_df.index\n",
    "# print \"\\nColumn Names: \\n\",enron_df.columns\n",
    "# print \"\\nColumn Data Type: \\n\",enron_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Task 2: Remove outliers and Other Bad Data__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAERCAYAAACU1LsdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVLBUJAkFQwFSVLBUJAkFQwFSVLh/wP1B+q3c2iFtAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xfb83dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### read in data dictionary, convert to numpy array\n",
    "features = [\"salary\", \"bonus\"]\n",
    "data = featureFormat(data_dict, features)\n",
    "\n",
    "### Add these lines ... to make your scatterplot: \n",
    "\n",
    "for point in data:\n",
    "    salary = point[0]\n",
    "    bonus = point[1]\n",
    "    matplotlib.pyplot.scatter( salary, bonus )\n",
    "\n",
    "matplotlib.pyplot.xlabel(\"salary\")\n",
    "matplotlib.pyplot.ylabel(\"bonus\")\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>nmiss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TOTAL</th>\n",
       "      <td>26704229.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32083396.0</td>\n",
       "      <td>309886585.0</td>\n",
       "      <td>311764000.0</td>\n",
       "      <td>97343619.0</td>\n",
       "      <td>130322299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7576788.0</td>\n",
       "      <td>434509511.0</td>\n",
       "      <td>...</td>\n",
       "      <td>83925000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42667589.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1398517.0</td>\n",
       "      <td>-27992891.0</td>\n",
       "      <td>48521928.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           salary  to_messages  deferral_payments  total_payments  \\\n",
       "Name                                                                \n",
       "TOTAL  26704229.0          NaN         32083396.0     309886585.0   \n",
       "\n",
       "       exercised_stock_options       bonus  restricted_stock  \\\n",
       "Name                                                           \n",
       "TOTAL              311764000.0  97343619.0       130322299.0   \n",
       "\n",
       "       shared_receipt_with_poi  restricted_stock_deferred  total_stock_value  \\\n",
       "Name                                                                           \n",
       "TOTAL                      NaN                 -7576788.0        434509511.0   \n",
       "\n",
       "       ...    loan_advances  from_messages       other  \\\n",
       "Name   ...                                               \n",
       "TOTAL  ...       83925000.0            NaN  42667589.0   \n",
       "\n",
       "       from_this_person_to_poi    poi  director_fees  deferred_income  \\\n",
       "Name                                                                    \n",
       "TOTAL                      NaN  False      1398517.0      -27992891.0   \n",
       "\n",
       "       long_term_incentive  from_poi_to_this_person  nmiss  \n",
       "Name                                                        \n",
       "TOTAL           48521928.0                      NaN      5  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outlier Identification\n",
    "# OLD: enron_df.loc[enron_df.salary>5000000]\n",
    "\n",
    "enron_df.loc[enron_df.salary > \\\n",
    "            enron_df.salary.mean() + (3 * enron_df.salary.std())]\n",
    "\n",
    "# enron_df.loc['THE TRAVEL AGENCY IN THE PARK', :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>nmiss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BADUM JAMES P</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178980.0</td>\n",
       "      <td>182466.0</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BELFER ROBERT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-102500.0</td>\n",
       "      <td>102500.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44093.0</td>\n",
       "      <td>-44093.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHATNAGAR SANJAY</th>\n",
       "      <td>NaN</td>\n",
       "      <td>523.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>2604490.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2604490.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLAKE JR. NORMAN P</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>113784.0</td>\n",
       "      <td>-113784.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROWN MICHAEL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1486.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49288.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>761.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAN RONNIE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32460.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-32460.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>98784.0</td>\n",
       "      <td>-98784.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHRISTODOULOU DIOMEDES</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5127155.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>950730.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6077885.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLINE KENNETH W</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>662086.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-472568.0</td>\n",
       "      <td>189518.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>NaN</td>\n",
       "      <td>764.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>651850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>386335.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1038185.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUNCAN JOHN H</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77492.0</td>\n",
       "      <td>371750.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>371750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>102492.0</td>\n",
       "      <td>-25000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOWLER PEGGY</th>\n",
       "      <td>NaN</td>\n",
       "      <td>517.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1324578.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560170.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1884748.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOY JOE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>181755.0</td>\n",
       "      <td>181755.0</td>\n",
       "      <td>343434.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>343434.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FUGH JOHN L</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50591.0</td>\n",
       "      <td>50591.0</td>\n",
       "      <td>176378.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176378.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GATHMANN WILLIAM D</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1753766.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>264013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-72419.0</td>\n",
       "      <td>1945360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GIBBS DANA R</th>\n",
       "      <td>NaN</td>\n",
       "      <td>169.0</td>\n",
       "      <td>504610.0</td>\n",
       "      <td>966522.0</td>\n",
       "      <td>2218275.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2218275.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>461912.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GILLIS JOHN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9803.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75838.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85641.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRAMM WENDY L</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119292.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>119292.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAUG DAVID L</th>\n",
       "      <td>NaN</td>\n",
       "      <td>573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>475.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2217299.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2217299.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAYES ROBERT E</th>\n",
       "      <td>NaN</td>\n",
       "      <td>504.0</td>\n",
       "      <td>7961.0</td>\n",
       "      <td>7961.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151418.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151418.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAYSLETT RODERICK J</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2649.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>346663.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>346663.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HIRKO JOSEPH</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10259.0</td>\n",
       "      <td>91093.0</td>\n",
       "      <td>30766064.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30766064.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2856.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HORTON STANLEY C</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2350.0</td>\n",
       "      <td>3131860.0</td>\n",
       "      <td>3131860.0</td>\n",
       "      <td>5210569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2046079.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7256648.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUGHES JAMES A</th>\n",
       "      <td>NaN</td>\n",
       "      <td>719.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>754966.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>363428.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1118394.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JAEDICKE ROBERT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83750.0</td>\n",
       "      <td>431750.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44093.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-44093.0</td>\n",
       "      <td>431750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>108750.0</td>\n",
       "      <td>-25000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEMAISTRE CHARLES</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87492.0</td>\n",
       "      <td>412878.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>412878.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>112492.0</td>\n",
       "      <td>-25000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEWIS RICHARD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>952.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>850477.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>739.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>850477.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOCKHART EUGENE E</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOWRY CHARLES P</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>372205.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153686.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-153686.0</td>\n",
       "      <td>372205.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCCARTY DANNY J</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1433.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>664375.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94556.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>758931.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCDONALD REBECCA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>894.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>757301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>934065.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1691366.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MENDELSOHN JOHN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>103750.0</td>\n",
       "      <td>-103750.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEYER JEROME J</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2151.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>38346.0</td>\n",
       "      <td>-38346.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEYER ROCKFORD G</th>\n",
       "      <td>NaN</td>\n",
       "      <td>232.0</td>\n",
       "      <td>1848227.0</td>\n",
       "      <td>1848227.0</td>\n",
       "      <td>493489.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>462384.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>955873.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MORAN MICHAEL P</th>\n",
       "      <td>NaN</td>\n",
       "      <td>672.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59539.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161602.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>221141.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOLES JAMES L</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>774401.0</td>\n",
       "      <td>774401.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>463261.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-94556.0</td>\n",
       "      <td>368705.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEREIRA PAULO V. FERRAZ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27942.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>101250.0</td>\n",
       "      <td>-101250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIRO JIM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47304.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47304.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POWERS WILLIAM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>653.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>17500.0</td>\n",
       "      <td>-17500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRENTICE JAMES</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>564348.0</td>\n",
       "      <td>564348.0</td>\n",
       "      <td>886231.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208809.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1095040.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAVAGE FRANK</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>125034.0</td>\n",
       "      <td>-121284.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCRIMSHAW MATTHEW</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>759557.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>759557.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHERRICK JEFFREY B</th>\n",
       "      <td>NaN</td>\n",
       "      <td>613.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1426469.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405999.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1832468.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THE TRAVEL AGENCY IN THE PARK</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>362096.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>362096.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URQUHART JOHN A</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>228656.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>36666.0</td>\n",
       "      <td>-36666.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAKEHAM JOHN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>213071.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>109298.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALTERS GARETH W</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53625.0</td>\n",
       "      <td>87410.0</td>\n",
       "      <td>1030329.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1030329.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHALEY DAVID A</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98718.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98718.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WINOKUR JR. HERBERT S</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84992.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>108579.0</td>\n",
       "      <td>-25000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WODRASKA JOHN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189583.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189583.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WROBEL BRUCE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAP SOON</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55097.0</td>\n",
       "      <td>192758.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192758.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               salary  to_messages  deferral_payments  \\\n",
       "Name                                                                    \n",
       "BADUM JAMES P                     NaN          NaN           178980.0   \n",
       "BELFER ROBERT                     NaN          NaN          -102500.0   \n",
       "BHATNAGAR SANJAY                  NaN        523.0                NaN   \n",
       "BLAKE JR. NORMAN P                NaN          NaN                NaN   \n",
       "BROWN MICHAEL                     NaN       1486.0                NaN   \n",
       "CHAN RONNIE                       NaN          NaN                NaN   \n",
       "CHRISTODOULOU DIOMEDES            NaN          NaN                NaN   \n",
       "CLINE KENNETH W                   NaN          NaN                NaN   \n",
       "CORDES WILLIAM R                  NaN        764.0                NaN   \n",
       "DUNCAN JOHN H                     NaN          NaN                NaN   \n",
       "FOWLER PEGGY                      NaN        517.0                NaN   \n",
       "FOY JOE                           NaN         57.0           181755.0   \n",
       "FUGH JOHN L                       NaN          NaN            50591.0   \n",
       "GATHMANN WILLIAM D                NaN          NaN                NaN   \n",
       "GIBBS DANA R                      NaN        169.0           504610.0   \n",
       "GILLIS JOHN                       NaN          NaN                NaN   \n",
       "GRAMM WENDY L                     NaN          NaN                NaN   \n",
       "HAUG DAVID L                      NaN        573.0                NaN   \n",
       "HAYES ROBERT E                    NaN        504.0             7961.0   \n",
       "HAYSLETT RODERICK J               NaN       2649.0                NaN   \n",
       "HIRKO JOSEPH                      NaN          NaN            10259.0   \n",
       "HORTON STANLEY C                  NaN       2350.0          3131860.0   \n",
       "HUGHES JAMES A                    NaN        719.0                NaN   \n",
       "JAEDICKE ROBERT                   NaN          NaN                NaN   \n",
       "LEMAISTRE CHARLES                 NaN          NaN                NaN   \n",
       "LEWIS RICHARD                     NaN        952.0                NaN   \n",
       "LOCKHART EUGENE E                 NaN          NaN                NaN   \n",
       "LOWRY CHARLES P                   NaN          NaN                NaN   \n",
       "MCCARTY DANNY J                   NaN       1433.0                NaN   \n",
       "MCDONALD REBECCA                  NaN        894.0                NaN   \n",
       "MENDELSOHN JOHN                   NaN          NaN                NaN   \n",
       "MEYER JEROME J                    NaN          NaN                NaN   \n",
       "MEYER ROCKFORD G                  NaN        232.0          1848227.0   \n",
       "MORAN MICHAEL P                   NaN        672.0                NaN   \n",
       "NOLES JAMES L                     NaN          NaN           774401.0   \n",
       "PEREIRA PAULO V. FERRAZ           NaN          NaN                NaN   \n",
       "PIRO JIM                          NaN         58.0                NaN   \n",
       "POWERS WILLIAM                    NaN        653.0                NaN   \n",
       "PRENTICE JAMES                    NaN          NaN           564348.0   \n",
       "SAVAGE FRANK                      NaN          NaN                NaN   \n",
       "SCRIMSHAW MATTHEW                 NaN          NaN                NaN   \n",
       "SHERRICK JEFFREY B                NaN        613.0                NaN   \n",
       "THE TRAVEL AGENCY IN THE PARK     NaN          NaN                NaN   \n",
       "URQUHART JOHN A                   NaN          NaN                NaN   \n",
       "WAKEHAM JOHN                      NaN          NaN                NaN   \n",
       "WALTERS GARETH W                  NaN          NaN            53625.0   \n",
       "WHALEY DAVID A                    NaN          NaN                NaN   \n",
       "WINOKUR JR. HERBERT S             NaN          NaN                NaN   \n",
       "WODRASKA JOHN                     NaN          NaN                NaN   \n",
       "WROBEL BRUCE                      NaN          NaN                NaN   \n",
       "YEAP SOON                         NaN          NaN                NaN   \n",
       "\n",
       "                               total_payments  exercised_stock_options  bonus  \\\n",
       "Name                                                                            \n",
       "BADUM JAMES P                        182466.0                 257817.0    NaN   \n",
       "BELFER ROBERT                        102500.0                   3285.0    NaN   \n",
       "BHATNAGAR SANJAY                   15456290.0                2604490.0    NaN   \n",
       "BLAKE JR. NORMAN P                     1279.0                      NaN    NaN   \n",
       "BROWN MICHAEL                         49288.0                      NaN    NaN   \n",
       "CHAN RONNIE                               NaN                      NaN    NaN   \n",
       "CHRISTODOULOU DIOMEDES                    NaN                5127155.0    NaN   \n",
       "CLINE KENNETH W                           NaN                      NaN    NaN   \n",
       "CORDES WILLIAM R                          NaN                 651850.0    NaN   \n",
       "DUNCAN JOHN H                         77492.0                 371750.0    NaN   \n",
       "FOWLER PEGGY                              NaN                1324578.0    NaN   \n",
       "FOY JOE                              181755.0                 343434.0    NaN   \n",
       "FUGH JOHN L                           50591.0                 176378.0    NaN   \n",
       "GATHMANN WILLIAM D                        NaN                1753766.0    NaN   \n",
       "GIBBS DANA R                         966522.0                2218275.0    NaN   \n",
       "GILLIS JOHN                               NaN                   9803.0    NaN   \n",
       "GRAMM WENDY L                        119292.0                      NaN    NaN   \n",
       "HAUG DAVID L                            475.0                      NaN    NaN   \n",
       "HAYES ROBERT E                         7961.0                      NaN    NaN   \n",
       "HAYSLETT RODERICK J                       NaN                      NaN    NaN   \n",
       "HIRKO JOSEPH                          91093.0               30766064.0    NaN   \n",
       "HORTON STANLEY C                    3131860.0                5210569.0    NaN   \n",
       "HUGHES JAMES A                            NaN                 754966.0    NaN   \n",
       "JAEDICKE ROBERT                       83750.0                 431750.0    NaN   \n",
       "LEMAISTRE CHARLES                     87492.0                 412878.0    NaN   \n",
       "LEWIS RICHARD                             NaN                 850477.0    NaN   \n",
       "LOCKHART EUGENE E                         NaN                      NaN    NaN   \n",
       "LOWRY CHARLES P                           NaN                 372205.0    NaN   \n",
       "MCCARTY DANNY J                           NaN                 664375.0    NaN   \n",
       "MCDONALD REBECCA                          NaN                 757301.0    NaN   \n",
       "MENDELSOHN JOHN                         148.0                      NaN    NaN   \n",
       "MEYER JEROME J                         2151.0                      NaN    NaN   \n",
       "MEYER ROCKFORD G                    1848227.0                 493489.0    NaN   \n",
       "MORAN MICHAEL P                           NaN                  59539.0    NaN   \n",
       "NOLES JAMES L                        774401.0                      NaN    NaN   \n",
       "PEREIRA PAULO V. FERRAZ               27942.0                      NaN    NaN   \n",
       "PIRO JIM                                  NaN                      NaN    NaN   \n",
       "POWERS WILLIAM                            NaN                      NaN    NaN   \n",
       "PRENTICE JAMES                       564348.0                 886231.0    NaN   \n",
       "SAVAGE FRANK                           3750.0                      NaN    NaN   \n",
       "SCRIMSHAW MATTHEW                         NaN                 759557.0    NaN   \n",
       "SHERRICK JEFFREY B                        NaN                1426469.0    NaN   \n",
       "THE TRAVEL AGENCY IN THE PARK        362096.0                      NaN    NaN   \n",
       "URQUHART JOHN A                      228656.0                      NaN    NaN   \n",
       "WAKEHAM JOHN                         213071.0                      NaN    NaN   \n",
       "WALTERS GARETH W                      87410.0                1030329.0    NaN   \n",
       "WHALEY DAVID A                            NaN                  98718.0    NaN   \n",
       "WINOKUR JR. HERBERT S                 84992.0                      NaN    NaN   \n",
       "WODRASKA JOHN                        189583.0                      NaN    NaN   \n",
       "WROBEL BRUCE                              NaN                 139130.0    NaN   \n",
       "YEAP SOON                             55097.0                 192758.0    NaN   \n",
       "\n",
       "                               restricted_stock  shared_receipt_with_poi  \\\n",
       "Name                                                                       \n",
       "BADUM JAMES P                               NaN                      NaN   \n",
       "BELFER ROBERT                               NaN                      NaN   \n",
       "BHATNAGAR SANJAY                     -2604490.0                    463.0   \n",
       "BLAKE JR. NORMAN P                          NaN                      NaN   \n",
       "BROWN MICHAEL                               NaN                    761.0   \n",
       "CHAN RONNIE                             32460.0                      NaN   \n",
       "CHRISTODOULOU DIOMEDES                 950730.0                      NaN   \n",
       "CLINE KENNETH W                        662086.0                      NaN   \n",
       "CORDES WILLIAM R                       386335.0                     58.0   \n",
       "DUNCAN JOHN H                               NaN                      NaN   \n",
       "FOWLER PEGGY                           560170.0                     10.0   \n",
       "FOY JOE                                     NaN                      2.0   \n",
       "FUGH JOHN L                                 NaN                      NaN   \n",
       "GATHMANN WILLIAM D                     264013.0                      NaN   \n",
       "GIBBS DANA R                                NaN                     23.0   \n",
       "GILLIS JOHN                             75838.0                      NaN   \n",
       "GRAMM WENDY L                               NaN                      NaN   \n",
       "HAUG DAVID L                          2217299.0                    471.0   \n",
       "HAYES ROBERT E                         151418.0                     50.0   \n",
       "HAYSLETT RODERICK J                    346663.0                    571.0   \n",
       "HIRKO JOSEPH                                NaN                      NaN   \n",
       "HORTON STANLEY C                      2046079.0                   1074.0   \n",
       "HUGHES JAMES A                         363428.0                    589.0   \n",
       "JAEDICKE ROBERT                         44093.0                      NaN   \n",
       "LEMAISTRE CHARLES                           NaN                      NaN   \n",
       "LEWIS RICHARD                               NaN                    739.0   \n",
       "LOCKHART EUGENE E                           NaN                      NaN   \n",
       "LOWRY CHARLES P                        153686.0                      NaN   \n",
       "MCCARTY DANNY J                         94556.0                    508.0   \n",
       "MCDONALD REBECCA                       934065.0                    720.0   \n",
       "MENDELSOHN JOHN                             NaN                      NaN   \n",
       "MEYER JEROME J                              NaN                      NaN   \n",
       "MEYER ROCKFORD G                       462384.0                     22.0   \n",
       "MORAN MICHAEL P                        161602.0                    127.0   \n",
       "NOLES JAMES L                          463261.0                      NaN   \n",
       "PEREIRA PAULO V. FERRAZ                     NaN                      NaN   \n",
       "PIRO JIM                                47304.0                      3.0   \n",
       "POWERS WILLIAM                              NaN                     12.0   \n",
       "PRENTICE JAMES                         208809.0                      NaN   \n",
       "SAVAGE FRANK                                NaN                      NaN   \n",
       "SCRIMSHAW MATTHEW                           NaN                      NaN   \n",
       "SHERRICK JEFFREY B                     405999.0                    583.0   \n",
       "THE TRAVEL AGENCY IN THE PARK               NaN                      NaN   \n",
       "URQUHART JOHN A                             NaN                      NaN   \n",
       "WAKEHAM JOHN                                NaN                      NaN   \n",
       "WALTERS GARETH W                            NaN                      NaN   \n",
       "WHALEY DAVID A                              NaN                      NaN   \n",
       "WINOKUR JR. HERBERT S                       NaN                      NaN   \n",
       "WODRASKA JOHN                               NaN                      NaN   \n",
       "WROBEL BRUCE                                NaN                      NaN   \n",
       "YEAP SOON                                   NaN                      NaN   \n",
       "\n",
       "                               restricted_stock_deferred  total_stock_value  \\\n",
       "Name                                                                          \n",
       "BADUM JAMES P                                        NaN           257817.0   \n",
       "BELFER ROBERT                                    44093.0           -44093.0   \n",
       "BHATNAGAR SANJAY                              15456290.0                NaN   \n",
       "BLAKE JR. NORMAN P                                   NaN                NaN   \n",
       "BROWN MICHAEL                                        NaN                NaN   \n",
       "CHAN RONNIE                                     -32460.0                NaN   \n",
       "CHRISTODOULOU DIOMEDES                               NaN          6077885.0   \n",
       "CLINE KENNETH W                                -472568.0           189518.0   \n",
       "CORDES WILLIAM R                                     NaN          1038185.0   \n",
       "DUNCAN JOHN H                                        NaN           371750.0   \n",
       "FOWLER PEGGY                                         NaN          1884748.0   \n",
       "FOY JOE                                              NaN           343434.0   \n",
       "FUGH JOHN L                                          NaN           176378.0   \n",
       "GATHMANN WILLIAM D                              -72419.0          1945360.0   \n",
       "GIBBS DANA R                                         NaN          2218275.0   \n",
       "GILLIS JOHN                                          NaN            85641.0   \n",
       "GRAMM WENDY L                                        NaN                NaN   \n",
       "HAUG DAVID L                                         NaN          2217299.0   \n",
       "HAYES ROBERT E                                       NaN           151418.0   \n",
       "HAYSLETT RODERICK J                                  NaN           346663.0   \n",
       "HIRKO JOSEPH                                         NaN         30766064.0   \n",
       "HORTON STANLEY C                                     NaN          7256648.0   \n",
       "HUGHES JAMES A                                       NaN          1118394.0   \n",
       "JAEDICKE ROBERT                                 -44093.0           431750.0   \n",
       "LEMAISTRE CHARLES                                    NaN           412878.0   \n",
       "LEWIS RICHARD                                        NaN           850477.0   \n",
       "LOCKHART EUGENE E                                    NaN                NaN   \n",
       "LOWRY CHARLES P                                -153686.0           372205.0   \n",
       "MCCARTY DANNY J                                      NaN           758931.0   \n",
       "MCDONALD REBECCA                                     NaN          1691366.0   \n",
       "MENDELSOHN JOHN                                      NaN                NaN   \n",
       "MEYER JEROME J                                       NaN                NaN   \n",
       "MEYER ROCKFORD G                                     NaN           955873.0   \n",
       "MORAN MICHAEL P                                      NaN           221141.0   \n",
       "NOLES JAMES L                                   -94556.0           368705.0   \n",
       "PEREIRA PAULO V. FERRAZ                              NaN                NaN   \n",
       "PIRO JIM                                             NaN            47304.0   \n",
       "POWERS WILLIAM                                       NaN                NaN   \n",
       "PRENTICE JAMES                                       NaN          1095040.0   \n",
       "SAVAGE FRANK                                         NaN                NaN   \n",
       "SCRIMSHAW MATTHEW                                    NaN           759557.0   \n",
       "SHERRICK JEFFREY B                                   NaN          1832468.0   \n",
       "THE TRAVEL AGENCY IN THE PARK                        NaN                NaN   \n",
       "URQUHART JOHN A                                      NaN                NaN   \n",
       "WAKEHAM JOHN                                         NaN                NaN   \n",
       "WALTERS GARETH W                                     NaN          1030329.0   \n",
       "WHALEY DAVID A                                       NaN            98718.0   \n",
       "WINOKUR JR. HERBERT S                                NaN                NaN   \n",
       "WODRASKA JOHN                                        NaN                NaN   \n",
       "WROBEL BRUCE                                         NaN           139130.0   \n",
       "YEAP SOON                                            NaN           192758.0   \n",
       "\n",
       "                               ...    loan_advances  from_messages     other  \\\n",
       "Name                           ...                                             \n",
       "BADUM JAMES P                  ...              NaN            NaN       NaN   \n",
       "BELFER ROBERT                  ...              NaN            NaN       NaN   \n",
       "BHATNAGAR SANJAY               ...              NaN           29.0  137864.0   \n",
       "BLAKE JR. NORMAN P             ...              NaN            NaN       NaN   \n",
       "BROWN MICHAEL                  ...              NaN           41.0       NaN   \n",
       "CHAN RONNIE                    ...              NaN            NaN       NaN   \n",
       "CHRISTODOULOU DIOMEDES         ...              NaN            NaN       NaN   \n",
       "CLINE KENNETH W                ...              NaN            NaN       NaN   \n",
       "CORDES WILLIAM R               ...              NaN           12.0       NaN   \n",
       "DUNCAN JOHN H                  ...              NaN            NaN       NaN   \n",
       "FOWLER PEGGY                   ...              NaN           36.0       NaN   \n",
       "FOY JOE                        ...              NaN           13.0       NaN   \n",
       "FUGH JOHN L                    ...              NaN            NaN       NaN   \n",
       "GATHMANN WILLIAM D             ...              NaN            NaN       NaN   \n",
       "GIBBS DANA R                   ...              NaN           12.0       NaN   \n",
       "GILLIS JOHN                    ...              NaN            NaN       NaN   \n",
       "GRAMM WENDY L                  ...              NaN            NaN       NaN   \n",
       "HAUG DAVID L                   ...              NaN           19.0       NaN   \n",
       "HAYES ROBERT E                 ...              NaN           12.0       NaN   \n",
       "HAYSLETT RODERICK J            ...              NaN         1061.0       NaN   \n",
       "HIRKO JOSEPH                   ...              NaN            NaN    2856.0   \n",
       "HORTON STANLEY C               ...              NaN         1073.0       NaN   \n",
       "HUGHES JAMES A                 ...              NaN           34.0       NaN   \n",
       "JAEDICKE ROBERT                ...              NaN            NaN       NaN   \n",
       "LEMAISTRE CHARLES              ...              NaN            NaN       NaN   \n",
       "LEWIS RICHARD                  ...              NaN           26.0       NaN   \n",
       "LOCKHART EUGENE E              ...              NaN            NaN       NaN   \n",
       "LOWRY CHARLES P                ...              NaN            NaN       NaN   \n",
       "MCCARTY DANNY J                ...              NaN          215.0       NaN   \n",
       "MCDONALD REBECCA               ...              NaN           13.0       NaN   \n",
       "MENDELSOHN JOHN                ...              NaN            NaN       NaN   \n",
       "MEYER JEROME J                 ...              NaN            NaN       NaN   \n",
       "MEYER ROCKFORD G               ...              NaN           28.0       NaN   \n",
       "MORAN MICHAEL P                ...              NaN           19.0       NaN   \n",
       "NOLES JAMES L                  ...              NaN            NaN       NaN   \n",
       "PEREIRA PAULO V. FERRAZ        ...              NaN            NaN       NaN   \n",
       "PIRO JIM                       ...              NaN           16.0       NaN   \n",
       "POWERS WILLIAM                 ...              NaN           26.0       NaN   \n",
       "PRENTICE JAMES                 ...              NaN            NaN       NaN   \n",
       "SAVAGE FRANK                   ...              NaN            NaN       NaN   \n",
       "SCRIMSHAW MATTHEW              ...              NaN            NaN       NaN   \n",
       "SHERRICK JEFFREY B             ...              NaN           25.0       NaN   \n",
       "THE TRAVEL AGENCY IN THE PARK  ...              NaN            NaN  362096.0   \n",
       "URQUHART JOHN A                ...              NaN            NaN       NaN   \n",
       "WAKEHAM JOHN                   ...              NaN            NaN       NaN   \n",
       "WALTERS GARETH W               ...              NaN            NaN       NaN   \n",
       "WHALEY DAVID A                 ...              NaN            NaN       NaN   \n",
       "WINOKUR JR. HERBERT S          ...              NaN            NaN       NaN   \n",
       "WODRASKA JOHN                  ...              NaN            NaN  189583.0   \n",
       "WROBEL BRUCE                   ...              NaN            NaN       NaN   \n",
       "YEAP SOON                      ...              NaN            NaN       NaN   \n",
       "\n",
       "                               from_this_person_to_poi    poi  director_fees  \\\n",
       "Name                                                                           \n",
       "BADUM JAMES P                                      NaN  False            NaN   \n",
       "BELFER ROBERT                                      NaN  False         3285.0   \n",
       "BHATNAGAR SANJAY                                   1.0  False       137864.0   \n",
       "BLAKE JR. NORMAN P                                 NaN  False       113784.0   \n",
       "BROWN MICHAEL                                      1.0  False            NaN   \n",
       "CHAN RONNIE                                        NaN  False        98784.0   \n",
       "CHRISTODOULOU DIOMEDES                             NaN  False            NaN   \n",
       "CLINE KENNETH W                                    NaN  False            NaN   \n",
       "CORDES WILLIAM R                                   0.0  False            NaN   \n",
       "DUNCAN JOHN H                                      NaN  False       102492.0   \n",
       "FOWLER PEGGY                                       0.0  False            NaN   \n",
       "FOY JOE                                            0.0  False            NaN   \n",
       "FUGH JOHN L                                        NaN  False            NaN   \n",
       "GATHMANN WILLIAM D                                 NaN  False            NaN   \n",
       "GIBBS DANA R                                       0.0  False            NaN   \n",
       "GILLIS JOHN                                        NaN  False            NaN   \n",
       "GRAMM WENDY L                                      NaN  False       119292.0   \n",
       "HAUG DAVID L                                       7.0  False            NaN   \n",
       "HAYES ROBERT E                                     0.0  False            NaN   \n",
       "HAYSLETT RODERICK J                               38.0  False            NaN   \n",
       "HIRKO JOSEPH                                       NaN   True            NaN   \n",
       "HORTON STANLEY C                                  15.0  False            NaN   \n",
       "HUGHES JAMES A                                     5.0  False            NaN   \n",
       "JAEDICKE ROBERT                                    NaN  False       108750.0   \n",
       "LEMAISTRE CHARLES                                  NaN  False       112492.0   \n",
       "LEWIS RICHARD                                      0.0  False            NaN   \n",
       "LOCKHART EUGENE E                                  NaN  False            NaN   \n",
       "LOWRY CHARLES P                                    NaN  False            NaN   \n",
       "MCCARTY DANNY J                                    2.0  False            NaN   \n",
       "MCDONALD REBECCA                                   1.0  False            NaN   \n",
       "MENDELSOHN JOHN                                    NaN  False       103750.0   \n",
       "MEYER JEROME J                                     NaN  False        38346.0   \n",
       "MEYER ROCKFORD G                                   0.0  False            NaN   \n",
       "MORAN MICHAEL P                                    0.0  False            NaN   \n",
       "NOLES JAMES L                                      NaN  False            NaN   \n",
       "PEREIRA PAULO V. FERRAZ                            NaN  False       101250.0   \n",
       "PIRO JIM                                           1.0  False            NaN   \n",
       "POWERS WILLIAM                                     0.0  False        17500.0   \n",
       "PRENTICE JAMES                                     NaN  False            NaN   \n",
       "SAVAGE FRANK                                       NaN  False       125034.0   \n",
       "SCRIMSHAW MATTHEW                                  NaN  False            NaN   \n",
       "SHERRICK JEFFREY B                                18.0  False            NaN   \n",
       "THE TRAVEL AGENCY IN THE PARK                      NaN  False            NaN   \n",
       "URQUHART JOHN A                                    NaN  False        36666.0   \n",
       "WAKEHAM JOHN                                       NaN  False       109298.0   \n",
       "WALTERS GARETH W                                   NaN  False            NaN   \n",
       "WHALEY DAVID A                                     NaN  False            NaN   \n",
       "WINOKUR JR. HERBERT S                              NaN  False       108579.0   \n",
       "WODRASKA JOHN                                      NaN  False            NaN   \n",
       "WROBEL BRUCE                                       NaN  False            NaN   \n",
       "YEAP SOON                                          NaN  False            NaN   \n",
       "\n",
       "                               deferred_income  long_term_incentive  \\\n",
       "Name                                                                  \n",
       "BADUM JAMES P                              NaN                  NaN   \n",
       "BELFER ROBERT                              NaN                  NaN   \n",
       "BHATNAGAR SANJAY                           NaN                  NaN   \n",
       "BLAKE JR. NORMAN P                   -113784.0                  NaN   \n",
       "BROWN MICHAEL                              NaN                  NaN   \n",
       "CHAN RONNIE                           -98784.0                  NaN   \n",
       "CHRISTODOULOU DIOMEDES                     NaN                  NaN   \n",
       "CLINE KENNETH W                            NaN                  NaN   \n",
       "CORDES WILLIAM R                           NaN                  NaN   \n",
       "DUNCAN JOHN H                         -25000.0                  NaN   \n",
       "FOWLER PEGGY                               NaN                  NaN   \n",
       "FOY JOE                                    NaN                  NaN   \n",
       "FUGH JOHN L                                NaN                  NaN   \n",
       "GATHMANN WILLIAM D                         NaN                  NaN   \n",
       "GIBBS DANA R                               NaN             461912.0   \n",
       "GILLIS JOHN                                NaN                  NaN   \n",
       "GRAMM WENDY L                              NaN                  NaN   \n",
       "HAUG DAVID L                               NaN                  NaN   \n",
       "HAYES ROBERT E                             NaN                  NaN   \n",
       "HAYSLETT RODERICK J                        NaN                  NaN   \n",
       "HIRKO JOSEPH                               NaN                  NaN   \n",
       "HORTON STANLEY C                           NaN                  NaN   \n",
       "HUGHES JAMES A                             NaN                  NaN   \n",
       "JAEDICKE ROBERT                       -25000.0                  NaN   \n",
       "LEMAISTRE CHARLES                     -25000.0                  NaN   \n",
       "LEWIS RICHARD                              NaN                  NaN   \n",
       "LOCKHART EUGENE E                          NaN                  NaN   \n",
       "LOWRY CHARLES P                            NaN                  NaN   \n",
       "MCCARTY DANNY J                            NaN                  NaN   \n",
       "MCDONALD REBECCA                           NaN                  NaN   \n",
       "MENDELSOHN JOHN                      -103750.0                  NaN   \n",
       "MEYER JEROME J                        -38346.0                  NaN   \n",
       "MEYER ROCKFORD G                           NaN                  NaN   \n",
       "MORAN MICHAEL P                            NaN                  NaN   \n",
       "NOLES JAMES L                              NaN                  NaN   \n",
       "PEREIRA PAULO V. FERRAZ              -101250.0                  NaN   \n",
       "PIRO JIM                                   NaN                  NaN   \n",
       "POWERS WILLIAM                        -17500.0                  NaN   \n",
       "PRENTICE JAMES                             NaN                  NaN   \n",
       "SAVAGE FRANK                         -121284.0                  NaN   \n",
       "SCRIMSHAW MATTHEW                          NaN                  NaN   \n",
       "SHERRICK JEFFREY B                         NaN                  NaN   \n",
       "THE TRAVEL AGENCY IN THE PARK              NaN                  NaN   \n",
       "URQUHART JOHN A                       -36666.0                  NaN   \n",
       "WAKEHAM JOHN                               NaN                  NaN   \n",
       "WALTERS GARETH W                           NaN                  NaN   \n",
       "WHALEY DAVID A                             NaN                  NaN   \n",
       "WINOKUR JR. HERBERT S                 -25000.0                  NaN   \n",
       "WODRASKA JOHN                              NaN                  NaN   \n",
       "WROBEL BRUCE                               NaN                  NaN   \n",
       "YEAP SOON                                  NaN                  NaN   \n",
       "\n",
       "                               from_poi_to_this_person  nmiss  \n",
       "Name                                                           \n",
       "BADUM JAMES P                                      NaN     14  \n",
       "BELFER ROBERT                                      NaN     13  \n",
       "BHATNAGAR SANJAY                                   0.0      8  \n",
       "BLAKE JR. NORMAN P                                 NaN     15  \n",
       "BROWN MICHAEL                                     13.0     12  \n",
       "CHAN RONNIE                                        NaN     15  \n",
       "CHRISTODOULOU DIOMEDES                             NaN     16  \n",
       "CLINE KENNETH W                                    NaN     16  \n",
       "CORDES WILLIAM R                                  10.0     11  \n",
       "DUNCAN JOHN H                                      NaN     14  \n",
       "FOWLER PEGGY                                       0.0     11  \n",
       "FOY JOE                                            0.0     10  \n",
       "FUGH JOHN L                                        NaN     15  \n",
       "GATHMANN WILLIAM D                                 NaN     15  \n",
       "GIBBS DANA R                                       0.0      9  \n",
       "GILLIS JOHN                                        NaN     16  \n",
       "GRAMM WENDY L                                      NaN     17  \n",
       "HAUG DAVID L                                       4.0     10  \n",
       "HAYES ROBERT E                                    16.0     10  \n",
       "HAYSLETT RODERICK J                               35.0     12  \n",
       "HIRKO JOSEPH                                       NaN     13  \n",
       "HORTON STANLEY C                                  44.0      9  \n",
       "HUGHES JAMES A                                    35.0     11  \n",
       "JAEDICKE ROBERT                                    NaN     12  \n",
       "LEMAISTRE CHARLES                                  NaN     14  \n",
       "LEWIS RICHARD                                     10.0     12  \n",
       "LOCKHART EUGENE E                                  NaN     19  \n",
       "LOWRY CHARLES P                                    NaN     15  \n",
       "MCCARTY DANNY J                                   25.0     11  \n",
       "MCDONALD REBECCA                                  54.0     11  \n",
       "MENDELSOHN JOHN                                    NaN     15  \n",
       "MEYER JEROME J                                     NaN     15  \n",
       "MEYER ROCKFORD G                                   0.0      9  \n",
       "MORAN MICHAEL P                                    0.0     11  \n",
       "NOLES JAMES L                                      NaN     14  \n",
       "PEREIRA PAULO V. FERRAZ                            NaN     15  \n",
       "PIRO JIM                                           0.0     12  \n",
       "POWERS WILLIAM                                     0.0     12  \n",
       "PRENTICE JAMES                                     NaN     14  \n",
       "SAVAGE FRANK                                       NaN     16  \n",
       "SCRIMSHAW MATTHEW                                  NaN     17  \n",
       "SHERRICK JEFFREY B                                39.0     11  \n",
       "THE TRAVEL AGENCY IN THE PARK                      NaN     17  \n",
       "URQUHART JOHN A                                    NaN     15  \n",
       "WAKEHAM JOHN                                       NaN     16  \n",
       "WALTERS GARETH W                                   NaN     14  \n",
       "WHALEY DAVID A                                     NaN     17  \n",
       "WINOKUR JR. HERBERT S                              NaN     15  \n",
       "WODRASKA JOHN                                      NaN     17  \n",
       "WROBEL BRUCE                                       NaN     17  \n",
       "YEAP SOON                                          NaN     15  \n",
       "\n",
       "[51 rows x 21 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Based on concerns about missing data, I looked into their believability\n",
    "# Wheh filter to NaN salary, I discovered a \"THE TRAVEL AGENCY IN THE PARK\"\n",
    "enron_df[pd.isnull(enron_df.salary)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAAEKCAYAAABQRFHsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEYmVEpGIiMRKiUhERGKlRCQiIrH6/4lw3FIdlKZsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xfd34ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Removing \"TOTAL\" & \"THE TRAVEL AGENCY IN THE PARK\"\n",
    "data_dict.pop('TOTAL', 0)\n",
    "data_dict.pop('THE TRAVEL AGENCY IN THE PARK', 0)\n",
    "data_dict.pop('LOCKHART EUGENE E', 0)\n",
    "\n",
    "data = featureFormat(data_dict, features)\n",
    "\n",
    "for point in data:\n",
    "    salary = point[0]\n",
    "    bonus = point[1]\n",
    "    matplotlib.pyplot.scatter( salary, bonus )\n",
    "    \n",
    "matplotlib.pyplot.xlabel(\"salary\")\n",
    "matplotlib.pyplot.ylabel(\"bonus\")\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>nmiss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALLEN PHILLIP K</th>\n",
       "      <td>201955.0</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>2869717.0</td>\n",
       "      <td>4484442.0</td>\n",
       "      <td>1729541.0</td>\n",
       "      <td>4175000.0</td>\n",
       "      <td>126027.0</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>-126027.0</td>\n",
       "      <td>1729541.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3081055.0</td>\n",
       "      <td>304805.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BELDEN TIMOTHY N</th>\n",
       "      <td>213999.0</td>\n",
       "      <td>7991.0</td>\n",
       "      <td>2144013.0</td>\n",
       "      <td>5501630.0</td>\n",
       "      <td>953136.0</td>\n",
       "      <td>5249999.0</td>\n",
       "      <td>157569.0</td>\n",
       "      <td>5521.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1110705.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>484.0</td>\n",
       "      <td>210698.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2334434.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>228.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FREVERT MARK A</th>\n",
       "      <td>1060932.0</td>\n",
       "      <td>3275.0</td>\n",
       "      <td>6426990.0</td>\n",
       "      <td>17252530.0</td>\n",
       "      <td>10433518.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>4188667.0</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14622185.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7427621.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3367011.0</td>\n",
       "      <td>1617011.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KITCHEN LOUISE</th>\n",
       "      <td>271442.0</td>\n",
       "      <td>8305.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3471141.0</td>\n",
       "      <td>81042.0</td>\n",
       "      <td>3100000.0</td>\n",
       "      <td>466101.0</td>\n",
       "      <td>3669.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>547143.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1728.0</td>\n",
       "      <td>93925.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAVORATO JOHN J</th>\n",
       "      <td>339288.0</td>\n",
       "      <td>7259.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10425757.0</td>\n",
       "      <td>4158995.0</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>1008149.0</td>\n",
       "      <td>3962.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5167144.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2035380.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAY KENNETH L</th>\n",
       "      <td>1072321.0</td>\n",
       "      <td>4273.0</td>\n",
       "      <td>202911.0</td>\n",
       "      <td>103559793.0</td>\n",
       "      <td>34348384.0</td>\n",
       "      <td>7000000.0</td>\n",
       "      <td>14761694.0</td>\n",
       "      <td>2411.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49110078.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81525000.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10359729.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-300000.0</td>\n",
       "      <td>3600000.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PICKERING MARK R</th>\n",
       "      <td>655037.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1386690.0</td>\n",
       "      <td>28798.0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>728.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28798.0</td>\n",
       "      <td>...</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKILLING JEFFREY K</th>\n",
       "      <td>1111258.0</td>\n",
       "      <td>3627.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8682716.0</td>\n",
       "      <td>19250000.0</td>\n",
       "      <td>5600000.0</td>\n",
       "      <td>6843672.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26093672.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.0</td>\n",
       "      <td>22122.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1920000.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTAL</th>\n",
       "      <td>26704229.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32083396.0</td>\n",
       "      <td>309886585.0</td>\n",
       "      <td>311764000.0</td>\n",
       "      <td>97343619.0</td>\n",
       "      <td>130322299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7576788.0</td>\n",
       "      <td>434509511.0</td>\n",
       "      <td>...</td>\n",
       "      <td>83925000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42667589.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1398517.0</td>\n",
       "      <td>-27992891.0</td>\n",
       "      <td>48521928.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHALLEY LAWRENCE G</th>\n",
       "      <td>510364.0</td>\n",
       "      <td>6019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4677574.0</td>\n",
       "      <td>3282960.0</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>2796177.0</td>\n",
       "      <td>3920.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6079137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>556.0</td>\n",
       "      <td>301026.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>808346.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        salary  to_messages  deferral_payments  \\\n",
       "Name                                                             \n",
       "ALLEN PHILLIP K       201955.0       2902.0          2869717.0   \n",
       "BELDEN TIMOTHY N      213999.0       7991.0          2144013.0   \n",
       "FREVERT MARK A       1060932.0       3275.0          6426990.0   \n",
       "KITCHEN LOUISE        271442.0       8305.0                NaN   \n",
       "LAVORATO JOHN J       339288.0       7259.0                NaN   \n",
       "LAY KENNETH L        1072321.0       4273.0           202911.0   \n",
       "PICKERING MARK R      655037.0        898.0                NaN   \n",
       "SKILLING JEFFREY K   1111258.0       3627.0                NaN   \n",
       "TOTAL               26704229.0          NaN         32083396.0   \n",
       "WHALLEY LAWRENCE G    510364.0       6019.0                NaN   \n",
       "\n",
       "                    total_payments  exercised_stock_options       bonus  \\\n",
       "Name                                                                      \n",
       "ALLEN PHILLIP K          4484442.0                1729541.0   4175000.0   \n",
       "BELDEN TIMOTHY N         5501630.0                 953136.0   5249999.0   \n",
       "FREVERT MARK A          17252530.0               10433518.0   2000000.0   \n",
       "KITCHEN LOUISE           3471141.0                  81042.0   3100000.0   \n",
       "LAVORATO JOHN J         10425757.0                4158995.0   8000000.0   \n",
       "LAY KENNETH L          103559793.0               34348384.0   7000000.0   \n",
       "PICKERING MARK R         1386690.0                  28798.0    300000.0   \n",
       "SKILLING JEFFREY K       8682716.0               19250000.0   5600000.0   \n",
       "TOTAL                  309886585.0              311764000.0  97343619.0   \n",
       "WHALLEY LAWRENCE G       4677574.0                3282960.0   3000000.0   \n",
       "\n",
       "                    restricted_stock  shared_receipt_with_poi  \\\n",
       "Name                                                            \n",
       "ALLEN PHILLIP K             126027.0                   1407.0   \n",
       "BELDEN TIMOTHY N            157569.0                   5521.0   \n",
       "FREVERT MARK A             4188667.0                   2979.0   \n",
       "KITCHEN LOUISE              466101.0                   3669.0   \n",
       "LAVORATO JOHN J            1008149.0                   3962.0   \n",
       "LAY KENNETH L             14761694.0                   2411.0   \n",
       "PICKERING MARK R                 NaN                    728.0   \n",
       "SKILLING JEFFREY K         6843672.0                   2042.0   \n",
       "TOTAL                    130322299.0                      NaN   \n",
       "WHALLEY LAWRENCE G         2796177.0                   3920.0   \n",
       "\n",
       "                    restricted_stock_deferred  total_stock_value  ...    \\\n",
       "Name                                                              ...     \n",
       "ALLEN PHILLIP K                     -126027.0          1729541.0  ...     \n",
       "BELDEN TIMOTHY N                          NaN          1110705.0  ...     \n",
       "FREVERT MARK A                            NaN         14622185.0  ...     \n",
       "KITCHEN LOUISE                            NaN           547143.0  ...     \n",
       "LAVORATO JOHN J                           NaN          5167144.0  ...     \n",
       "LAY KENNETH L                             NaN         49110078.0  ...     \n",
       "PICKERING MARK R                          NaN            28798.0  ...     \n",
       "SKILLING JEFFREY K                        NaN         26093672.0  ...     \n",
       "TOTAL                              -7576788.0        434509511.0  ...     \n",
       "WHALLEY LAWRENCE G                        NaN          6079137.0  ...     \n",
       "\n",
       "                    loan_advances  from_messages       other  \\\n",
       "Name                                                           \n",
       "ALLEN PHILLIP K               NaN         2195.0       152.0   \n",
       "BELDEN TIMOTHY N              NaN          484.0    210698.0   \n",
       "FREVERT MARK A          2000000.0           21.0   7427621.0   \n",
       "KITCHEN LOUISE                NaN         1728.0     93925.0   \n",
       "LAVORATO JOHN J               NaN         2585.0      1552.0   \n",
       "LAY KENNETH L          81525000.0           36.0  10359729.0   \n",
       "PICKERING MARK R         400000.0           67.0         NaN   \n",
       "SKILLING JEFFREY K            NaN          108.0     22122.0   \n",
       "TOTAL                  83925000.0            NaN  42667589.0   \n",
       "WHALLEY LAWRENCE G            NaN          556.0    301026.0   \n",
       "\n",
       "                    from_this_person_to_poi    poi  director_fees  \\\n",
       "Name                                                                \n",
       "ALLEN PHILLIP K                        65.0  False            NaN   \n",
       "BELDEN TIMOTHY N                      108.0   True            NaN   \n",
       "FREVERT MARK A                          6.0  False            NaN   \n",
       "KITCHEN LOUISE                        194.0  False            NaN   \n",
       "LAVORATO JOHN J                       411.0  False            NaN   \n",
       "LAY KENNETH L                          16.0   True            NaN   \n",
       "PICKERING MARK R                        0.0  False            NaN   \n",
       "SKILLING JEFFREY K                     30.0   True            NaN   \n",
       "TOTAL                                   NaN  False      1398517.0   \n",
       "WHALLEY LAWRENCE G                     24.0  False            NaN   \n",
       "\n",
       "                    deferred_income  long_term_incentive  \\\n",
       "Name                                                       \n",
       "ALLEN PHILLIP K          -3081055.0             304805.0   \n",
       "BELDEN TIMOTHY N         -2334434.0                  NaN   \n",
       "FREVERT MARK A           -3367011.0            1617011.0   \n",
       "KITCHEN LOUISE                  NaN                  NaN   \n",
       "LAVORATO JOHN J                 NaN            2035380.0   \n",
       "LAY KENNETH L             -300000.0            3600000.0   \n",
       "PICKERING MARK R                NaN                  NaN   \n",
       "SKILLING JEFFREY K              NaN            1920000.0   \n",
       "TOTAL                   -27992891.0           48521928.0   \n",
       "WHALLEY LAWRENCE G              NaN             808346.0   \n",
       "\n",
       "                    from_poi_to_this_person  nmiss  \n",
       "Name                                                \n",
       "ALLEN PHILLIP K                        47.0      2  \n",
       "BELDEN TIMOTHY N                      228.0      4  \n",
       "FREVERT MARK A                        242.0      2  \n",
       "KITCHEN LOUISE                        251.0      6  \n",
       "LAVORATO JOHN J                       528.0      5  \n",
       "LAY KENNETH L                         123.0      2  \n",
       "PICKERING MARK R                        7.0      7  \n",
       "SKILLING JEFFREY K                     88.0      5  \n",
       "TOTAL                                   NaN      5  \n",
       "WHALLEY LAWRENCE G                    186.0      5  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Keep the remaining outliers?\n",
    "enron_df[(enron_df.salary>500000) | (enron_df.bonus>3000000)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Is it plausible that all these individuals got huge salary and/or bonus?* **Yes!**\n",
    "\n",
    "* ALLEN PHILLIP K: He \"received a $4.4 million bonus\" (Barboza, 2002).\n",
    "\n",
    "* BELDEN TIMOTHY N: Mr. Belden, \"an executive on the power desk in Portland, Ore., got a $5.2 million bonus\" (Barboza, 2002).\n",
    "\n",
    "* FREVERT MARK A: Enron vice chairman.\n",
    "\n",
    "* KITCHEN LOUISE: A \"young British trader spearheading Enron's entry into Europe's energy markets\"\n",
    "* LAVORATO JOHN J: Top Executive\n",
    "* LAY KENNETH L: Kenneth L. Lay, the company's former chairman and chief executive.\n",
    "* PICKERING MARK R: Chief Technology Officer\n",
    "* SKILLING JEFFREY K: Former Enron president and CEO\n",
    "* TOTAL: Removed from *data_dict*\n",
    "* WHALLEY LAWRENCE G: Enron president and chief operating officer\n",
    "\n",
    "_References:_\n",
    "\n",
    "Officials Got a Windfall Before Enron's Collapse, By David Barboza. June 18, 2002: https://www.nytimes.com/2002/06/18/business/officials-got-a-windfall-before-enron-s-collapse.html\n",
    "\n",
    "The Guardian. Enron Key Players. January 12, 2002: https://www.theguardian.com/business/2002/jan/13/corporatefraud.enron\n",
    "\n",
    "Los Angeles Times. Enron's Run Tripped by Arrogance, Greed. By David Streitfel and Lee Romney. January 27, 2002: http://articles.latimes.com/2002/jan/27/news/mn-25002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocation Across Classes (POI/non-POI)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>poi</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>66</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferral_payments</th>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferred_income</th>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director_fees</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <td>90</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expenses</th>\n",
       "      <td>77</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_messages</th>\n",
       "      <td>72</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <td>72</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <td>72</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_advances</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_term_incentive</th>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nmiss</th>\n",
       "      <td>128</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>75</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock</th>\n",
       "      <td>93</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>78</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <td>72</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_messages</th>\n",
       "      <td>72</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_payments</th>\n",
       "      <td>107</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_stock_value</th>\n",
       "      <td>108</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "poi                        False  True \n",
       "bonus                         66     16\n",
       "deferral_payments             34      5\n",
       "deferred_income               38     11\n",
       "director_fees                 17      0\n",
       "exercised_stock_options       90     12\n",
       "expenses                      77     18\n",
       "from_messages                 72     14\n",
       "from_poi_to_this_person       72     14\n",
       "from_this_person_to_poi       72     14\n",
       "loan_advances                  3      1\n",
       "long_term_incentive           54     12\n",
       "nmiss                        128     18\n",
       "other                         75     18\n",
       "restricted_stock              93     17\n",
       "restricted_stock_deferred     18      0\n",
       "salary                        78     17\n",
       "shared_receipt_with_poi       72     14\n",
       "to_messages                   72     14\n",
       "total_payments               107     18\n",
       "total_stock_value            108     18"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count, by POI\n",
    "print \"Allocation Across Classes (POI/non-POI)\"\n",
    "enron_df.pivot_table(index='poi',aggfunc='count').transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Task 3: Create new feature(s)**\n",
    "_plus Feature Reduction_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "### Created Features ...\n",
    "\n",
    "def fraction_calc( numerator, denominator ):\n",
    "    if numerator == 'NaN' or denominator == 'NaN':\n",
    "        fraction = 0\n",
    "    else:\n",
    "        fraction = float(numerator)/float(denominator)    \n",
    "    return round(fraction, 2)\n",
    "    \n",
    "    \n",
    "def fraction_to_dict(dictionary, numerator, denominator, new_feature_name):\n",
    "    num = dictionary[numerator]\n",
    "    den = dictionary[denominator]\n",
    "    fraction = fraction_calc(num, den)\n",
    "    dictionary[new_feature_name] = fraction\n",
    "    return dictionary\n",
    "    \n",
    "for p in my_dataset:      \n",
    "    # New Feature: Total Stocks to Salary Ratio\n",
    "    my_dataset[p] = fraction_to_dict(my_dataset[p],\n",
    "                                        'total_stock_value',\n",
    "                                        'salary',\n",
    "                                        'stock_to_salary_ratio') \n",
    "                                        \n",
    "    \n",
    "features_financial = features_financial + ['stock_to_salary_ratio']\n",
    "\n",
    "features_list = ['poi'] + features_financial + features_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Array Length: 143 (v. 146 in the original data)\n",
      "\n",
      "Features List: ['poi', 'salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock', 'director_fees', 'stock_to_salary_ratio', 'to_messages', 'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi']\n"
     ]
    }
   ],
   "source": [
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "print \"Numpy Array Length:\", len(data), \"(v. 146 in the original data)\"\n",
    "print \"\\nFeatures List:\", features_list\n",
    "#print \"Labels:\", labels\n",
    "#print \"Features:\", features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Ideal Number of Features_\n",
    "\n",
    "We utilized SelectKBest and GridSearchCV to arrive at an ideal number of selected features for this Machine Learning analysis. Based on this analysis, the ideal number of features is 13. If we follow this recommendation strictly, we should go with features with top 13 SelectKBest scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ideal Features: {'kbest__k': 13}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "features_financial = features_financial + ['stock_to_salary_ratio']\n",
    "features_list = ['poi'] + features_financial + features_email\n",
    "\n",
    "kbest = SelectKBest(f_classif)\n",
    "pipeline = Pipeline([('kbest', kbest), ('lr', LogisticRegression())])\n",
    "grid_search = GridSearchCV(pipeline, {'kbest__k': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]})\n",
    "grid_search.fit(features, labels)\n",
    "print \"Number of Ideal Features:\", grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Feature Selction: Selecting Best Features for Analyses_\n",
    "\n",
    "Features with 13 top scores were (highest score is listed first): \n",
    "*'exercised_stock_options', 'total_stock_value', 'bonus','salary', 'deferred_income', \n",
    "'long_term_incentive', 'restricted_stock', 'total_payments', 'from_this_person_to_poi', 'loan_advances', \n",
    "'expenses', 'to_messages', 'other'*\n",
    "\n",
    "We decided to exclude 'total_stock_value' and 'total_payments' because we expected them to be highly correlated with their compoenents. For instance, we expected 'exercised_stock_options' and 'total_stock_value' to be correlated because the former is a component of the latter.\n",
    "\n",
    "So, we got down to selecting features with top 11 SelectKBest: \n",
    "*'exercised_stock_options', 'bonus','salary', 'deferred_income', \n",
    "'long_term_incentive', 'restricted_stock', 'total_payments', 'from_this_person_to_poi', 'loan_advances', \n",
    "'expenses', 'to_messages', 'other'*\n",
    "\n",
    "When we ran a Naive Bayes algorighm on these 11 features, we obtained this error message:\n",
    "*\"The least populated class in y has only 1 member, which is too few. The minimum number of labels for any class cannot be less than 2.\"*\n",
    "\n",
    "If given more time, we would explore how many variables or principal components would be adequate in explaining the outcome variable. We have seen some analyses at work where programmers compared number of features vs. percentage of variance explained. Analysts were supposed to select a number of principal components that explains anywhere from 85% to 95% of variance.\n",
    "\n",
    "For this project, we resorted to top 3 features after excluding total_stock_value. We decided this based on the SelectKBest scores and the error message when features with many \"NaN\" values were included - e.g. deferred_income has only 49 (34%) non-NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 best features: ['salary', 'to_messages', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', 'director_fees', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'from_poi_to_this_person', 'exercised_stock_options', 'from_messages', 'other', 'stock_to_salary_ratio', 'deferred_income', 'restricted_stock', 'long_term_incentive']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('exercised_stock_options', 24.815079733218194),\n",
       " ('total_stock_value', 24.182898678566879),\n",
       " ('bonus', 20.792252047181535),\n",
       " ('salary', 18.289684043404513),\n",
       " ('deferred_income', 11.458476579280369),\n",
       " ('long_term_incentive', 9.9221860131898225),\n",
       " ('restricted_stock', 9.2128106219771002),\n",
       " ('total_payments', 8.7727777300916756),\n",
       " ('from_messages', 8.589420731682381),\n",
       " ('loan_advances', 7.1840556582887247),\n",
       " ('expenses', 6.0941733106389453),\n",
       " ('other', 4.1874775069953749),\n",
       " ('from_poi_to_this_person', 2.3826121082276739),\n",
       " ('director_fees', 2.1263278020077054),\n",
       " ('deferral_payments', 0.22461127473600989),\n",
       " ('to_messages', 0.16970094762175533),\n",
       " ('stock_to_salary_ratio', 0.11734992795655314),\n",
       " ('restricted_stock_deferred', 0.065499652909942141)]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Univariate Feature Selection\n",
    "import sklearn.feature_selection\n",
    "\n",
    "features_financial = features_financial + ['stock_to_salary_ratio']\n",
    "features_list = ['poi'] + features_financial + features_email\n",
    "\n",
    "knum=20\n",
    "\n",
    "k_best = sklearn.feature_selection.SelectKBest(k=knum)\n",
    "k_best.fit(features, labels)\n",
    "scores = k_best.scores_\n",
    "unsorted_pairs = zip(features_list[1:], scores)\n",
    "sorted_pairs = list(reversed(sorted(unsorted_pairs, key=lambda x: x[1])))\n",
    "k_best_features = dict(sorted_pairs[:knum])\n",
    "print knum,\"best features: {0}\\n\".format(k_best_features.keys())\n",
    "k_best_features\n",
    "\n",
    "import operator\n",
    "#sorted(k_best_features.keys())\n",
    "#sorted(x.items(), key=operator.itemgetter(1))\n",
    "sorted(k_best_features.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*New Feature*: Stock-Salary Ratio\n",
    "\n",
    "We created a stock-salary ratio with the thought that a high stock-salary ratio would be an indication that a person may know about the wrong-doings of the company that they may buy or sell their stocks at the right time. \n",
    "\n",
    "However, this ratio was not one of the features with high SelectKBest scores. In fact, the ratio ranked 19th (highest) among all features. \n",
    "\n",
    "***\n",
    "\n",
    "**Task 4: Try a varity of classifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "# Provided to give you a starting point... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I considered using the word bags aka text learning. Not sure if this would be useful because crooks may encrypt their wordings and there are definite other means of communication that are not examined here. e.g. phone, F2F.\n",
    "\n",
    "I would have tried a regression analysis. However, obvioiusly a linear regression model is not appropiate for a 'POI vs. non-POI' analysis, i.e. the outcome variable is a binary variable. If I was given more time, I would explore a Logistic Regression model, which was not covered in this course. Personally, I am not clear on why Logistic Regression analysis was not covered in the course given that such analysis would have taken a 1-2 hours of lecture time. Besides the time constraint, I am happy to limit myself to the basic unsupervised machine learning methods.     \n",
    "\n",
    "Thus, I resort to these machine learning algorithms:\n",
    "1. Naive Bayes\n",
    "2. Support vector machine\n",
    "3. Decision Tree Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Totals: 4.0\n",
      "Accuracy = 0.884\n",
      "Acc = 0.884\n",
      "Prec = 0.500\n",
      "Rec = 0.400\n",
      "\n",
      "Confusion Matrix [0 v. 1]: \n",
      "[[36  2]\n",
      " [ 3  2]]\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "Tester Classification\n",
      "\n",
      "GaussianNB(priors=None)\n",
      "\tAccuracy: 0.84277\tPrecision: 0.48281\tRecall: 0.30900\tF1: 0.37683\tF2: 0.33297\n",
      "\tTotal predictions: 13000\tTrue positives:  618\tFalse positives:  662\tFalse negatives: 1382\tTrue negatives: 10338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 1. Naive Bayes (default parameters)\n",
    "\n",
    "features_list = ['poi', 'exercised_stock_options','bonus','salary'] \n",
    "# features_list = [ 'exercised_stock_options', 'bonus','salary', 'deferred_income', \\\n",
    "#                  'long_term_incentive', 'restricted_stock', 'total_payments', \\\n",
    "#                  'from_this_person_to_poi', 'loan_advances', 'expenses', 'to_messages', 'other']\n",
    "\n",
    "# Test Size\n",
    "features_train, features_test, labels_train, labels_test \\\n",
    "= train_test_split(features, labels, test_size=0.30, random_state=42)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, labels_train)\n",
    "predict = clf.predict(features_test)\n",
    "accuracy = accuracy_score(predict, labels_test)\n",
    "acc = accuracy_score(labels_test, predict)\n",
    "prec = precision_score(labels_test, predict)\n",
    "recall = recall_score(labels_test, predict)\n",
    "\n",
    "print \"Prediction Totals:\", sum(predict) \n",
    "print \"Accuracy =\",(\"{0:.3f}\".format(accuracy))\n",
    "print \"Acc =\",(\"{0:.3f}\".format(acc))\n",
    "print \"Prec =\",(\"{0:.3f}\".format(prec))\n",
    "print \"Rec =\",(\"{0:.3f}\".format(recall))\n",
    "\n",
    "print \"\\nConfusion Matrix [0 v. 1]: \\n\",confusion_matrix(labels_test, predict)\n",
    "\n",
    "print \"\\n-----------------------------------------------\" \n",
    "print \"\\nTester Classification\\n\" \n",
    "test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Totals: 0.0\n",
      "Accuracy = 0.884\n",
      "Acc = 0.884\n",
      "Prec = 0.000\n",
      "Rec = 0.000\n",
      "\n",
      "Confusion Matrix [0 v. 1]: \n",
      "[[38  0]\n",
      " [ 5  0]]\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "Tester Classification\n",
      "\n",
      "Got a divide by zero when trying out: SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Precision or recall may be undefined due to a lack of true positive predicitons.\n"
     ]
    }
   ],
   "source": [
    "### 2. SVM (default parameters)\n",
    "\n",
    "features_list = ['poi', 'exercised_stock_options','bonus','salary'] \n",
    "\n",
    "# Test Size\n",
    "features_train, features_test, labels_train, labels_test \\\n",
    "= train_test_split(features, labels, test_size=0.30, random_state=42)\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(features_train, labels_train)\n",
    "predict = clf.predict(features_test)\n",
    "accuracy = accuracy_score(predict, labels_test)\n",
    "acc = accuracy_score(labels_test, predict)\n",
    "prec = precision_score(labels_test, predict)\n",
    "recall = recall_score(labels_test, predict)\n",
    "\n",
    "print \"Prediction Totals:\", sum(predict) \n",
    "print \"Accuracy =\",(\"{0:.3f}\".format(accuracy))\n",
    "print \"Acc =\",(\"{0:.3f}\".format(acc))\n",
    "print \"Prec =\",(\"{0:.3f}\".format(prec))\n",
    "print \"Rec =\",(\"{0:.3f}\".format(recall))\n",
    "\n",
    "print \"\\nConfusion Matrix [0 v. 1]: \\n\",confusion_matrix(labels_test, predict)\n",
    "\n",
    "print \"\\n-----------------------------------------------\" \n",
    "print \"\\nTester Classification\\n\" \n",
    "test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Totals: 3.0\n",
      "Accuracy = 0.860\n",
      "Acc = 0.860\n",
      "Prec = 0.333\n",
      "Rec = 0.200\n",
      "\n",
      "Confusion Matrix [0 v. 1]: \n",
      "[[36  2]\n",
      " [ 4  1]]\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "Tester Classification\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.76977\tPrecision: 0.29200\tRecall: 0.34850\tF1: 0.31776\tF2: 0.33552\n",
      "\tTotal predictions: 13000\tTrue positives:  697\tFalse positives: 1690\tFalse negatives: 1303\tTrue negatives: 9310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 3. Decision Tree Classifier (default parameters)\n",
    "\n",
    "features_list = ['poi', 'exercised_stock_options','bonus','salary'] \n",
    "\n",
    "# Test Size\n",
    "features_train, features_test, labels_train, labels_test \\\n",
    "= train_test_split(features, labels, test_size=0.30, random_state=42)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(features_train, labels_train)\n",
    "predict = clf.predict(features_test)\n",
    "accuracy = accuracy_score(predict, labels_test)\n",
    "acc = accuracy_score(labels_test, predict)\n",
    "prec = precision_score(labels_test, predict)\n",
    "recall = recall_score(labels_test, predict)\n",
    "\n",
    "print \"Prediction Totals:\", sum(predict) \n",
    "print \"Accuracy =\",(\"{0:.3f}\".format(accuracy))\n",
    "print \"Acc =\",(\"{0:.3f}\".format(acc))\n",
    "print \"Prec =\",(\"{0:.3f}\".format(prec))\n",
    "print \"Rec =\",(\"{0:.3f}\".format(recall))\n",
    "\n",
    "print \"\\nConfusion Matrix [0 v. 1]: \\n\",confusion_matrix(labels_test, predict)\n",
    "\n",
    "print \"\\n-----------------------------------------------\" \n",
    "print \"\\nTester Classification\\n\" \n",
    "test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the default parameters, Naive Bayes actually met the to meeting the 0.3 Precision and Recall standards and Decision Tree Classifier were close. We expected that algorithms' performance improve with fine tunings and scaling. \n",
    "\n",
    "***\n",
    "\n",
    "**Task 5: Tune your classifier**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Totals: 4.0\n",
      "Accuracy = 0.884\n",
      "Acc = 0.884\n",
      "Prec = 0.500\n",
      "Rec = 0.400\n",
      "\n",
      "Confusion Matrix [0 v. 1]: \n",
      "[[36  2]\n",
      " [ 3  2]]\n",
      "-----------------------------------------------\n",
      "\n",
      "Tester Classification\n",
      "\n",
      "GaussianNB(priors=None)\n",
      "\tAccuracy: 0.84277\tPrecision: 0.48281\tRecall: 0.30900\tF1: 0.37683\tF2: 0.33297\n",
      "\tTotal predictions: 13000\tTrue positives:  618\tFalse positives:  662\tFalse negatives: 1382\tTrue negatives: 10338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "\n",
    "#1. Naive Bayes \n",
    "# No tuning available with the Naive Bayes method\n",
    "\n",
    "features_list = ['poi', 'exercised_stock_options','bonus','salary'] \n",
    "# features_list = ['poi', 'exercised_stock_options','bonus','salary','deferred_income','long_term_incentive','restricted_stock'] \n",
    "\n",
    "# Test Size\n",
    "features_train, features_test, labels_train, labels_test \\\n",
    "= train_test_split(features, labels, test_size=0.30, random_state=42)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, labels_train)\n",
    "predict = clf.predict(features_test)\n",
    "accuracy = accuracy_score(predict, labels_test)\n",
    "acc = accuracy_score(labels_test, predict)\n",
    "prec = precision_score(labels_test, predict)\n",
    "recall = recall_score(labels_test, predict)\n",
    "\n",
    "print \"Prediction Totals:\", sum(predict) \n",
    "print \"Accuracy =\",(\"{0:.3f}\".format(accuracy))\n",
    "print \"Acc =\",(\"{0:.3f}\".format(acc))\n",
    "print \"Prec =\",(\"{0:.3f}\".format(prec))\n",
    "print \"Rec =\",(\"{0:.3f}\".format(recall))\n",
    "\n",
    "print \"\\nConfusion Matrix [0 v. 1]: \\n\",confusion_matrix(labels_test, predict)\n",
    "\n",
    "print \"-----------------------------------------------\" \n",
    "\n",
    "print \"\\nTester Classification\\n\" \n",
    "test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM Tuned Up\n",
    "\n",
    "We have four cells dealing with SVM. Its short story:\n",
    "1. SVM does not do a good job when tune ups include altering C, gamma, and SVM parameters. All our results' precision and recall metrics were 0.000.\n",
    "2. SVM performs good when MinMaxSclaler() scaler transformation was applied.\n",
    "\n",
    "_a. SVM without a Scaler Transformation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C | gamma | svmpar | n_pred | acc | prec | recall \n",
      "---------------------------------------------------------\n",
      "0.01 1 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.01 1 sigmoid 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.01 0.1 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.01 0.1 sigmoid 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.01 0.01 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.01 0.01 sigmoid 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.01 0.001 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.01 0.001 sigmoid 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.01 0.0001 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.01 0.0001 sigmoid 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.1 1 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.1 1 sigmoid 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.1 0.1 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.1 0.1 sigmoid 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.1 0.01 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.1 0.01 sigmoid 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.1 0.001 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.1 0.001 sigmoid 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.1 0.0001 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "0.1 0.0001 sigmoid 0.0 0.884 0.000 0.000 \n",
      "\n",
      "1 1 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "1 1 sigmoid 2.0 0.837 0.000 0.000 \n",
      "\n",
      "1 0.1 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "1 0.1 sigmoid 2.0 0.837 0.000 0.000 \n",
      "\n",
      "1 0.01 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "1 0.01 sigmoid 2.0 0.837 0.000 0.000 \n",
      "\n",
      "1 0.001 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "1 0.001 sigmoid 2.0 0.837 0.000 0.000 \n",
      "\n",
      "1 0.0001 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "1 0.0001 sigmoid 2.0 0.837 0.000 0.000 \n",
      "\n",
      "10 1 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "10 1 sigmoid 3.0 0.814 0.000 0.000 \n",
      "\n",
      "10 0.1 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "10 0.1 sigmoid 3.0 0.814 0.000 0.000 \n",
      "\n",
      "10 0.01 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "10 0.01 sigmoid 3.0 0.814 0.000 0.000 \n",
      "\n",
      "10 0.001 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "10 0.001 sigmoid 3.0 0.814 0.000 0.000 \n",
      "\n",
      "10 0.0001 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "10 0.0001 sigmoid 3.0 0.814 0.000 0.000 \n",
      "\n",
      "100 1 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "100 1 sigmoid 3.0 0.814 0.000 0.000 \n",
      "\n",
      "100 0.1 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "100 0.1 sigmoid 3.0 0.814 0.000 0.000 \n",
      "\n",
      "100 0.01 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "100 0.01 sigmoid 3.0 0.814 0.000 0.000 \n",
      "\n",
      "100 0.001 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "100 0.001 sigmoid 3.0 0.814 0.000 0.000 \n",
      "\n",
      "100 0.0001 rbf 0.0 0.884 0.000 0.000 \n",
      "\n",
      "100 0.0001 sigmoid 3.0 0.814 0.000 0.000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 2. SVM (Tuned Up, but Unscaled)\n",
    "\n",
    "features_list = ['poi', 'exercised_stock_options','bonus','salary'] \n",
    "# features_list = ['poi', 'exercised_stock_options','bonus','salary','deferred_income','long_term_incentive','restricted_stock'] \n",
    "\n",
    "C = [0.01, 0.1, 1, 10, 100]\n",
    "gamma_list = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "svm_param = ['rbf', 'sigmoid'] # kernel; rbf the fastest\n",
    "# n_sample = [0.3, 0.35, 0.4, 0.5] # kernel; rbf the fastest\n",
    "\n",
    "# for ccc in C\n",
    "print \"C | gamma | svmpar | n_pred | acc | prec | recall \"\n",
    "print \"---------------------------------------------------------\" \n",
    "\n",
    "# a more hands on approach for my understanding \n",
    "# especially on which parameters having the largest impact\n",
    "for ccc in C:\n",
    "    for ggg in gamma_list:\n",
    "        for svmpar in svm_param:\n",
    "            # for nnn in n_sample:\n",
    "                # Test Size\n",
    "            features_train, features_test, labels_train, labels_test \\\n",
    "            = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "            clf = SVC(kernel=svmpar, C = ccc, gamma=ggg)\n",
    "            clf.fit(features_train, labels_train)\n",
    "            predict = clf.predict(features_test)\n",
    "            acc = accuracy_score(labels_test, predict)\n",
    "            prec = precision_score(labels_test, predict)\n",
    "            recall = recall_score(labels_test, predict)\n",
    "\n",
    "            print ccc, ggg, svmpar,sum(predict),(\"{0:.3f}\".format(acc)), \\\n",
    "            (\"{0:.3f}\".format(prec)), (\"{0:.3f}\".format(recall)),\"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.1 sigmoid 3.0 0.814 0.000 0.000 \n",
      "\n",
      "\n",
      "Confusion Matrix [0 v. 1]: \n",
      "[[35  3]\n",
      " [ 5  0]]\n",
      "\n",
      "Tester Classification\n",
      "\n",
      "Got a divide by zero when trying out: SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.1, kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Precision or recall may be undefined due to a lack of true positive predicitons.\n"
     ]
    }
   ],
   "source": [
    "# SVM doesn't do a great job in predicting\n",
    "# various sets of parameters result in 0.000 precision and recall scores\n",
    "# The unsclaes SVM also suffers from \"lack of true positive predicitons\"\n",
    "\n",
    "features_list = ['poi', 'exercised_stock_options','bonus','salary'] \n",
    "\n",
    "# Test Size\n",
    "features_train, features_test, labels_train, labels_test \\\n",
    "= train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "ccc = 100 # C\n",
    "ggg = 0.1  # gamma_list\n",
    "svmpar = 'sigmoid' # svm_param = ['rbf', 'sigmoid']; kernel; rbf the fastest\n",
    "\n",
    "clf = SVC(kernel=svmpar, C = ccc, gamma=ggg)\n",
    "clf.fit(features_train, labels_train)\n",
    "predict = clf.predict(features_test)\n",
    "acc = accuracy_score(labels_test, predict)\n",
    "prec = precision_score(labels_test, predict)\n",
    "recall = recall_score(labels_test, predict)\n",
    "\n",
    "print ccc, ggg, svmpar,sum(predict),(\"{0:.3f}\".format(acc)), \\\n",
    "(\"{0:.3f}\".format(prec)), (\"{0:.3f}\".format(recall)),\"\\n\"\n",
    "print \"\\nConfusion Matrix [0 v. 1]: \\n\",confusion_matrix(labels_test, predict)\n",
    "print \"\\nTester Classification\\n\" \n",
    "test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_b. SVM with a Scaler Transformation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WRONG?: Scaler Transform\n",
    "# SVM doesn't do a great job in predicting\n",
    "# various sets of parameters result in 0.000 precision and recall scores\n",
    "\n",
    "# # Apply standardization to SVM\n",
    "# features_trainX = scaler.fit(features_train).transform(features_train)\n",
    "# features_testX = scaler.fit(features_test).transform(features_test)\n",
    "\n",
    "# # Test Size\n",
    "# features_trainX, features_testX, labels_train, labels_test \\\n",
    "# = train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "\n",
      "Tester Classification\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('svm', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=2, gamma=1, kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "\tAccuracy: 0.85485\tPrecision: 0.63420\tRecall: 0.13350\tF1: 0.22057\tF2: 0.15853\n",
      "\tTotal predictions: 13000\tTrue positives:  267\tFalse positives:  154\tFalse negatives: 1733\tTrue negatives: 10846\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## SVM Model (Tuned Up and Scaled)\n",
    "from sklearn import svm\n",
    "\n",
    "### Min-Max Scaler ###\n",
    "# Very likely to be necessary due to wide ranges among variables\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "features_train, features_test, labels_train, labels_test \\\n",
    "            = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "svm = Pipeline([('scaler',preprocessing.MinMaxScaler()),('svm',svm.SVC())])\n",
    "param_grid = ([{'svm__C': [0.1, 1, 50, 100],\n",
    "                'svm__gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                'svm__degree':[1,2],\n",
    "                'svm__kernel': ['rbf','poly']}])\n",
    "\n",
    "svm_grid_search = GridSearchCV(svm, param_grid, scoring='recall').fit(features, labels).best_estimator_\n",
    "print \"---------------------------------------------------------\" \n",
    "print \"\\nTester Classification\\n\" \n",
    "tester.test_classifier(svm_grid_search, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C | gamma | svmpar | n_pred | acc | prec | recall \n",
      "\n",
      "10 1 sigmoid 2.0 0.884 0.500 0.200 \n",
      "\n",
      "\n",
      "Confusion Matrix [0 v. 1]: \n",
      "[[37  1]\n",
      " [ 4  1]]\n",
      "---------------------------------------------------------\n",
      "\n",
      "Tester Classification\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('svm', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=2, gamma=1, kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "\tAccuracy: 0.85485\tPrecision: 0.63420\tRecall: 0.13350\tF1: 0.22057\tF2: 0.15853\n",
      "\tTotal predictions: 13000\tTrue positives:  267\tFalse positives:  154\tFalse negatives: 1733\tTrue negatives: 10846\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 2. SVM Tested (Tuned Up and Scaled)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "features_list = ['poi', 'exercised_stock_options', 'bonus', 'salary'] \n",
    "\n",
    "# Apply standardization to SVM\n",
    "features_trainX = scaler.fit(features_train).transform(features_train)\n",
    "features_testX = scaler.fit(features_test).transform(features_test)\n",
    "\n",
    "# Test Size\n",
    "features_trainX, features_testX, labels_train, labels_test \\\n",
    "= train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "ccc = 10 # C\n",
    "ggg = 1  # gamma_list\n",
    "svmpar = 'sigmoid' # svm_param = ['rbf', 'sigmoid']; kernel; rbf the fastest\n",
    "\n",
    "clf = SVC(kernel=svmpar, C = ccc, gamma=ggg)\n",
    "clf.fit(features_trainX, labels_train)\n",
    "predict = clf.predict(features_testX)\n",
    "acc = accuracy_score(labels_test, predict)\n",
    "prec = precision_score(labels_test, predict)\n",
    "recall = recall_score(labels_test, predict)\n",
    "\n",
    "\n",
    "print \"C | gamma | svmpar | n_pred | acc | prec | recall \\n\"\n",
    "print ccc, ggg, svmpar,sum(predict),(\"{0:.3f}\".format(acc)), \\\n",
    "(\"{0:.3f}\".format(prec)), (\"{0:.3f}\".format(recall)),\"\\n\"\n",
    "\n",
    "print \"\\nConfusion Matrix [0 v. 1]: \\n\",confusion_matrix(labels_test, predict)\n",
    "print \"---------------------------------------------------------\" \n",
    "print \"\\nTester Classification\\n\" \n",
    "tester.test_classifier(svm_grid_search, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tester Classification\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=20,\n",
      "            max_features=None, max_leaf_nodes=40, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='random')\n",
      "\tAccuracy: 0.78208\tPrecision: 0.30938\tRecall: 0.33800\tF1: 0.32306\tF2: 0.33186\n",
      "\tTotal predictions: 13000\tTrue positives:  676\tFalse positives: 1509\tFalse negatives: 1324\tTrue negatives: 9491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 3. Decision Tree (Tuned Up)\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn import tree\n",
    "\n",
    "features_list = ['poi', 'exercised_stock_options','bonus','salary'] \n",
    "# features_list = ['poi', 'exercised_stock_options','bonus','salary','deferred_income','long_term_incentive','restricted_stock'] \n",
    "\n",
    "# Test Size\n",
    "features_train, features_test, labels_train, labels_test \\\n",
    "= train_test_split(features, labels, test_size=0.30, random_state=42)\n",
    "\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)  \n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'criterion': ('gini','entropy'),\n",
    "              'min_samples_split':[2, 3, 5, 10],\n",
    "                'max_depth':[5,7,10,15,20,25],\n",
    "                'max_leaf_nodes':[10,30,40],\n",
    "             'splitter':('best','random')}\n",
    "\n",
    "\n",
    "cv_strata = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
    "grid_search = GridSearchCV(dt, parameters, cv=cv_strata, scoring='f1')\n",
    "\n",
    "grid_search.fit(features, labels)\n",
    "clf = grid_search.best_estimator_\n",
    "\n",
    "from tester import test_classifier\n",
    "\n",
    "print \"Tester Classification\\n\" \n",
    "test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_What Happens if We Included the Created New Feature?_\n",
    "\n",
    "The reviewer suggested that I test my best model with the new, created feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tester Classification\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=20,\n",
      "            max_features=None, max_leaf_nodes=40, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='random')\n",
      "\tAccuracy: 0.78554\tPrecision: 0.31674\tRecall: 0.34050\tF1: 0.32819\tF2: 0.33547\n",
      "\tTotal predictions: 13000\tTrue positives:  681\tFalse positives: 1469\tFalse negatives: 1319\tTrue negatives: 9531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 3. Decision Tree with New Feature\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn import tree\n",
    "\n",
    "features_list = ['poi', 'exercised_stock_options','bonus','salary','stock_to_salary_ratio'] \n",
    "# features_list = ['poi', 'exercised_stock_options','bonus','salary','deferred_income','long_term_incentive','restricted_stock'] \n",
    "\n",
    "# Test Size\n",
    "features_train, features_test, labels_train, labels_test \\\n",
    "= train_test_split(features, labels, test_size=0.30, random_state=42)\n",
    "\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)  \n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'criterion': ('gini','entropy'),\n",
    "              'min_samples_split':[2, 3, 5, 10],\n",
    "                'max_depth':[5,7,10,15,20,25],\n",
    "                'max_leaf_nodes':[10,30,40],\n",
    "             'splitter':('best','random')}\n",
    "\n",
    "\n",
    "cv_strata = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
    "grid_search = GridSearchCV(dt, parameters, cv=cv_strata, scoring='f1')\n",
    "\n",
    "grid_search.fit(features, labels)\n",
    "clf = grid_search.best_estimator_\n",
    "\n",
    "from tester import test_classifier\n",
    "\n",
    "print \"Tester Classification\\n\" \n",
    "test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.81738</td>\n",
       "      <td>0.38789</td>\n",
       "      <td>0.3235</td>\n",
       "      <td>0.35278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>With the New Feature</th>\n",
       "      <td>0.79954</td>\n",
       "      <td>0.34268</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.33246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Accuracy  Precision  Recall       F1\n",
       "Decision Tree Classifier   0.81738    0.38789  0.3235  0.35278\n",
       "With the New Feature       0.79954    0.34268  0.3300  0.33246"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([[0.81738, 0.38789, 0.32350, 0.35278], \n",
    "              [0.79954, 0.34268, 0.33000, 0.33246]],\n",
    "             columns = ['Accuracy','Precision', 'Recall', 'F1'], \n",
    "             index = ['Decision Tree Classifier','With the New Feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new, created feature (stock-salary ratio) does not seem to enhance the best algorithm's performance. Recall may have increase by 2% but accuracy and precision suffered by larger percentages. So, consistent with SelectKBest findings, the stock-salary ratio feature is not an important feature in predicting POIs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix [0 v. 1]: \n",
      "[[27  7]\n",
      " [ 3  1]]\n",
      "---------------------------------------------------------\n",
      "\n",
      "Tester Classification\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=15,\n",
      "            max_features=None, max_leaf_nodes=10, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "\tAccuracy: 0.80615\tPrecision: 0.34597\tRecall: 0.29200\tF1: 0.31670\tF2: 0.30140\n",
      "\tTotal predictions: 13000\tTrue positives:  584\tFalse positives: 1104\tFalse negatives: 1416\tTrue negatives: 9896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final Best Model\n",
    "clf = tree.DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=15,\n",
    "            max_features=None, max_leaf_nodes=10, min_impurity_split=1e-07,\n",
    "            min_samples_leaf=1, min_samples_split=10,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best')\n",
    "clf.fit(features_train, labels_train)\n",
    "predict = clf.predict(features_test)\n",
    "acc = accuracy_score(labels_test, predict)\n",
    "prec = precision_score(labels_test, predict)\n",
    "recall = recall_score(labels_test, predict)\n",
    "\n",
    "print \"\\nConfusion Matrix [0 v. 1]: \\n\",confusion_matrix(labels_test, predict)\n",
    "print \"---------------------------------------------------------\" \n",
    "print \"\\nTester Classification\\n\" \n",
    "test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.84277</td>\n",
       "      <td>0.48281</td>\n",
       "      <td>0.3090</td>\n",
       "      <td>0.37683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.85485</td>\n",
       "      <td>0.63420</td>\n",
       "      <td>0.1335</td>\n",
       "      <td>0.22057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.81738</td>\n",
       "      <td>0.38789</td>\n",
       "      <td>0.3235</td>\n",
       "      <td>0.35278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Accuracy  Precision  Recall       F1\n",
       "Gaussian Naive Bayes       0.84277    0.48281  0.3090  0.37683\n",
       "SVM                        0.85485    0.63420  0.1335  0.22057\n",
       "Decision Tree Classifier   0.81738    0.38789  0.3235  0.35278"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([[0.84277, 0.48281,  0.30900, 0.37683], \n",
    "              [0.85485, 0.63420, 0.13350, 0.22057],\n",
    "              [0.81738, 0.38789, 0.32350, 0.35278]],\n",
    "             columns = ['Accuracy','Precision', 'Recall', 'F1'], \n",
    "             index = ['Gaussian Naive Bayes','SVM','Decision Tree Classifier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuned up Gaussian Naive bayes and Decision Tree Classifier models satisfied the 0.3 precision and recal recall requirements. \n",
    "\n",
    "NB actually performed quite well for an algorithm that seemed to me very rigid – because researchers can’t alter the parameters. In fact, NB performed slightly better for many of the performance metrics such as Accuracy (0.84 vs. 0.82 for Decision Tree Classifier). \n",
    "\n",
    "However, I am choosing Decision Tree Classifier as the best final model due to its flexibility and its ample room for improvement.\n",
    "\n",
    "***\n",
    "\n",
    "**Task 6: Dump your classifier, dataset, and features_list **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main References\n",
    "\n",
    "\n",
    "Decision Tree Classifier in Python using Scikit-learn: http://benalexkeen.com/decision-tree-classifier-in-python-using-scikit-learn/\n",
    "\n",
    "Helpful Python Code Snippets for Data Exploration in Pandas (Michael Salmon): https://medium.com/@msalmon00/helpful-python-code-snippets-for-data-exploration-in-pandas-b7c5aed5ecb9\n",
    "\n",
    "How does SelectKBest work?: https://datascience.stackexchange.com/questions/10773/how-does-selectkbest-work\n",
    "\n",
    "How to apply standardization to SVMs in scikit-learn?: https://stackoverflow.com/questions/14688391/how-to-apply-standardization-to-svms-in-scikit-learn\n",
    "\n",
    "How to compute precision, recall, accuracy and f1-score for the multiclass case with scikit learn?: https://stackoverflow.com/questions/31421413/how-to-compute-precision-recall-accuracy-and-f1-score-for-the-multiclass-case\n",
    "\n",
    "How to filter in NaN (pandas)?: https://stackoverflow.com/questions/25050141/how-to-filter-in-nan-pandas\n",
    "\n",
    "How to frame two for loops in list comprehension python: https://stackoverflow.com/questions/18551458/how-to-frame-two-for-loops-in-list-comprehension-python\n",
    "\n",
    "How to get a classifier's confidence score for a prediction in sklearn?: https://stackoverflow.com/questions/31129592/how-to-get-a-classifiers-confidence-score-for-a-prediction-in-sklearn\n",
    "\n",
    "Identify Fraud From Enron Data (Arjan Hada): https://arjan-hada.github.io/pages/about-me.html\n",
    "\n",
    "Los Angeles Times. Enron's Run Tripped by Arrogance, Greed. By David Streitfel and Lee Romney. January 27, 2002: http://articles.latimes.com/2002/jan/27/news/mn-25002\n",
    "\n",
    "Machine Learning with Python on the Enron Dataset - Investigating Fraud using Scikit-learn(William Koehrsen): https://medium.com/@williamkoehrsen/machine-learning-with-python-on-the-enron-dataset-8d71015be26d\n",
    "\n",
    "Officials Got a Windfall Before Enron's Collapse, By David Barboza. June 18, 2002: https://www.nytimes.com/2002/06/18/business/officials-got-a-windfall-before-enron-s-collapse.html\n",
    "\n",
    "Pandas: make pivot table with percentage: https://stackoverflow.com/questions/40301973/pandas-make-pivot-table-with-percentage\n",
    "\n",
    "The Guardian. Enron Key Players. January 12, 2002: https://www.theguardian.com/business/2002/jan/13/corporatefraud.enron\n",
    "\n",
    "Using iloc, loc, & ix to select rows and columns in Pandas DataFrames (Shane Lynn): https://www.shanelynn.ie/select-pandas-dataframe-rows-and-columns-using-iloc-loc-and-ix/\n",
    "\n",
    "Visualize feature selection in descending order with SelectKBest: https://stackoverflow.com/questions/40245277/visualize-feature-selection-in-descending-order-with-selectkbest\n",
    "\n",
    "Your First Machine Learning Project in Python Step-By-Step (Jason Brownlee): https://machinelearningmastery.com/machine-learning-in-python-step-by-step/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
