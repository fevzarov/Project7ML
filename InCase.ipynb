{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'featureFormat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d3e9e1fd79b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mfeatures_list000\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'poi'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfinancial_features\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0memail_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m### Extract features and labels from dataset for local testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatureFormat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargetFeatureSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'featureFormat' is not defined"
     ]
    }
   ],
   "source": [
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi',\n",
    "                 'salary',\n",
    "                 'pct_poi_inbound',\n",
    "                 'pct_poi_outbound'] \n",
    "                 \n",
    "financial_features = ['salary', 'deferral_payments', 'total_payments',\n",
    "                      'loan_advances', 'bonus', 'restricted_stock_deferred', \n",
    "                      'deferred_income', 'total_stock_value', 'expenses', \n",
    "                      'exercised_stock_options', 'other', \n",
    "                      'long_term_incentive', 'restricted_stock', \n",
    "                      'director_fees']\n",
    "                      \n",
    "email_features = ['to_messages', 'email_address', 'from_poi_to_this_person', \n",
    "                  'from_messages', 'from_this_person_to_poi', \n",
    "                  'shared_receipt_with_poi']\n",
    "email_features.remove('email_address')\n",
    "\n",
    "email_features = email_features + ['fraction_from_poi', 'fraction_to_poi']\n",
    "financial_features = financial_features + ['fraction_salary_total_payments']\n",
    "                  \n",
    "features_list000 = ['poi'] + financial_features + email_features\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. Naive Bayes\n",
    "features_list = ['poi','salary'] # You will need to use more features\n",
    "\n",
    "# Test Size\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "                                                            features, \n",
    "                                                            labels, \n",
    "                                                            test_size=0.40, \n",
    "                                                            random_state=42)\n",
    "\n",
    "clf = GaussianNB()\n",
    "t0 = time()\n",
    "\n",
    "clf.fit(features_train, labels_train)\n",
    "print \"Training time:\",(\"{0:.1f}\".format(time()-t0)),\"second(s)\"\n",
    "\n",
    "tpredict = time()\n",
    "predict = clf.predict(features_test)\n",
    "print \"Prediction run time:\",(\"{0:.1f}\".format(time()-tpredict)),\"second(s)\"\n",
    "accuracy = accuracy_score(predict, labels_test)\n",
    "print \"\\nAccuracy =\",(\"{0:.3f}\".format(accuracy)),\"\\n\\nModel:\\n\",clf\n",
    "\n",
    "print \"\\nPrediction Totals:\", sum(predict) \n",
    "\n",
    "print \"\\nConfusion Matrix [0 v. 1]: \\n\",confusion_matrix(labels_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### SVM\n",
    "\n",
    "def tune_params(grid_search, features, labels, params, iters = 80):\n",
    "    \"\"\" given a grid_search and parameters list (if exist) for a specific model,\n",
    "    along with features and labels list,\n",
    "    it tunes the algorithm using grid search and prints out the average evaluation metrics\n",
    "    results (accuracy, percision, recall) after performing the tuning for iter times,\n",
    "    and the best hyperparameters for the model\n",
    "    \"\"\"\n",
    "    acc = []\n",
    "    pre = []\n",
    "    recall = []\n",
    "    for i in range(iters):\n",
    "        features_train, features_test, labels_train, labels_test = \\\n",
    "        train_test_split(features, labels, test_size = 0.3, random_state = i)\n",
    "        grid_search.fit(features_train, labels_train)\n",
    "        predicts = grid_search.predict(features_test)\n",
    "\n",
    "        acc = acc + [accuracy_score(labels_test, predicts)] \n",
    "        pre = pre + [precision_score(labels_test, predicts)]\n",
    "        recall = recall + [recall_score(labels_test, predicts)]\n",
    "    print \"accuracy: {}\".format(np.mean(acc))\n",
    "    print \"precision: {}\".format(np.mean(pre))\n",
    "    print \"recall: {}\".format(np.mean(recall))\n",
    "\n",
    "    best_params = grid_search.best_estimator_.get_params()\n",
    "    for param_name in params.keys():\n",
    "        print(\"%s = %r, \" % (param_name, best_params[param_name]))\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import svm\n",
    "svm_clf = svm.SVC()\n",
    "svm_param = {'kernel':('linear', 'rbf', 'sigmoid'),\n",
    "'gamma': [1, 0.001], # [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "'C': [1, 10, 1000]} # [0.1, 1, 10, 100, 1000]\n",
    "svm_grid_search = GridSearchCV(estimator = svm_clf, param_grid = svm_param)\n",
    "\n",
    "### svm_grid_search\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ccc = 0.01\n",
    "ggg = 0.001\n",
    "svmpar = 'sigmoid'\n",
    "nnn = .4\n",
    "### ***************\n",
    "C = [0.01, 0.1, 1, 10, 100]\n",
    "# gamma_list = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "# svm_param = ['rbf', 'sigmoid'] # kernel; rbf the fastest\n",
    "\n",
    "features_list = ['exercised_stock_options', 'bonus', 'salary', 'restricted_stock', 'total_payments'] \n",
    "\n",
    "# Test Size\n",
    "features_train, features_test, labels_train, labels_test \\\n",
    "= train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "for ccc in C:\n",
    "    clf = SVC(kernel='sigmoid', C = ccc)\n",
    "    clf.fit(features_train, labels_train)\n",
    "    predict = clf.predict(features_test)\n",
    "    acc = accuracy_score(labels_test, predict)\n",
    "    prec = precision_score(labels_test, predict)\n",
    "    recall = recall_score(labels_test, predict)\n",
    "\n",
    "    print ccc,sum(predict),(\"{0:.3f}\".format(accuracy)), (\"{0:.3f}\".format(prec)), (\"{0:.3f}\".format(recall)),\"\\n\"\n",
    "    #print \"\\nConfusion Matrix [0 v. 1]: \\n\",confusion_matrix(labels_test, predict)\n",
    "    #print features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ccc = 0.01\n",
    "ggg = 0.001\n",
    "svmpar = 'sigmoid' \n",
    "nnn = .4\n",
    "### ***************\n",
    "# C = [0.01, 0.1, 1, 10, 100]\n",
    "gamma_list = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "# svm_param = ['rbf', 'sigmoid'] # kernel; rbf the fastest\n",
    "\n",
    "# features_list = ['poi','salary', 'total_stock_value', 'bonus'] \n",
    "features_list = ['exercised_stock_options', 'bonus', 'salary', 'restricted_stock', 'total_payments'] \n",
    "\n",
    "# Test Size\n",
    "features_train, features_test, labels_train, labels_test \\\n",
    "= train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "for ggg in gamma_list:\n",
    "    clf = SVC(kernel='sigmoid', C = 10, gamma=ggg)\n",
    "    clf.fit(features_train, labels_train)\n",
    "    predict = clf.predict(features_test)\n",
    "    acc = accuracy_score(labels_test, predict)\n",
    "    prec = precision_score(labels_test, predict)\n",
    "    recall = recall_score(labels_test, predict)\n",
    "\n",
    "    print ggg,sum(predict),(\"{0:.3f}\".format(accuracy)), (\"{0:.3f}\".format(prec)), (\"{0:.3f}\".format(recall)),\"\\n\"\n",
    "    #print \"\\nConfusion Matrix [0 v. 1]: \\n\",confusion_matrix(labels_test, predict)\n",
    "    #print features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 2. SVM --------\n",
    "\n",
    "features_list = ['poi', 'salary', 'bonus', 'total_stock_value'] \n",
    "\n",
    "C = [0.01, 0.1, 1, 10, 100]\n",
    "gamma_list = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "svm_param = ['rbf', 'sigmoid'] # kernel; rbf the fastest\n",
    "n_sample = [0.35, 0.4, 0.5, 0.65] # kernel; rbf the fastest\n",
    "\n",
    "# for ccc in C\n",
    "print \"test % | C | gamma | svmpar | n_pred | acc | prec | recall \\n\"\n",
    "\n",
    "for ccc in C:\n",
    "    for ggg in gamma_list:\n",
    "        for svmpar in svm_param:\n",
    "            for nnn in n_sample:\n",
    "                # Test Size\n",
    "                features_train, features_test, labels_train, labels_test \\\n",
    "                = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "                clf = SVC(kernel=svmpar, C = ccc)\n",
    "                clf.fit(features_train, labels_train)\n",
    "                predict = clf.predict(features_test)\n",
    "                acc = accuracy_score(labels_test, predict)\n",
    "                prec = precision_score(labels_test, predict)\n",
    "                recall = recall_score(labels_test, predict)\n",
    "\n",
    "                print nnn, ccc, ggg, svmpar,sum(predict),(\"{0:.3f}\".format(accuracy)), (\"{0:.3f}\".format(prec)), (\"{0:.3f}\".format(recall)),\"\\n\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 2. SVM --------\n",
    "\n",
    "features_list = ['poi', 'salary', 'bonus', 'total_stock_value'] \n",
    "\n",
    "\n",
    "features_train, features_test, labels_train, labels_test \\\n",
    "= train_test_split(features, labels, test_size=0.35, random_state=42)\n",
    "\n",
    "# the classifier & clf = SVC(kernel=kernel, C=C)\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# kernel > ‘linear’, ‘poly’, ‘rbf’ [default], ‘sigmoid’, ‘precomputed’ \n",
    "clf = SVC(C=100.0, gamma=0.0001, kernel='sigmoid')\n",
    " \n",
    "clf.fit(features_train, labels_train)\n",
    "predict = clf.predict(features_test)\n",
    "accuracy = accuracy_score(predict, labels_test)\n",
    "\n",
    "print \"Accuracy =\",(\"{0:.3f}\".format(accuracy)),\"\\n\\nModel:\\n\",clf\n",
    "print \"\\nConfusion Matrix [0 v. 1]: \\n\",confusion_matrix(labels_test, predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. Regressions\n",
    "\n",
    "features_list = [\"bonus\", \"salary\"]\n",
    "\n",
    "# Test Size\n",
    "# features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "#                                                             features, \n",
    "#                                                             labels, \n",
    "#                                                             test_size=0.40, \n",
    "#                                                             random_state=42)\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, remove_any_zeroes=True)\n",
    "target, features = targetFeatureSplit( data )\n",
    "\n",
    "### training-testing split needed in regression, just like classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.5, random_state=42)\n",
    "train_color = \"b\"\n",
    "test_color = \"r\"\n",
    "\n",
    "### Your regression goes here!\n",
    "### Please name it reg, so that the plotting code below picks it up and \n",
    "### plots it correctly. Don't forget to change the test_color above from \"b\" to\n",
    "### \"r\" to differentiate training points from test points.\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(feature_train, target_train)\n",
    "\n",
    "print \"m:\", reg.coef_[0]\n",
    "print \"c:\", reg.intercept_\n",
    "print \"Train Score:\", reg.score(feature_train, target_train)\n",
    "print \"Test Score:\", reg.score(feature_test, target_test)\n",
    "\n",
    "\n",
    "### draw the scatterplot, with color-coded training and testing points\n",
    "import matplotlib.pyplot as plt\n",
    "for feature, target in zip(feature_test, target_test):\n",
    "    plt.scatter( feature, target, color=test_color ) \n",
    "for feature, target in zip(feature_train, target_train):\n",
    "    plt.scatter( feature, target, color=train_color ) \n",
    "\n",
    "### labels for the legend\n",
    "plt.scatter(feature_test[0], target_test[0], color=test_color, label=\"test\")\n",
    "plt.scatter(feature_test[0], target_test[0], color=train_color, label=\"train\")\n",
    "\n",
    "\n",
    "### draw the regression line, once it's coded\n",
    "try:\n",
    "    plt.plot( feature_test, reg.predict(feature_test) )\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "reg.fit(feature_test, target_test)\n",
    "print \"m_woOutlier:\", reg.coef_[0]\n",
    "plt.plot(feature_train, reg.predict(feature_train), color=\"b\") # Outlier?\n",
    "plt.xlabel(features_list[1])\n",
    "plt.ylabel(features_list[0])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print \"\\nConfusion Matrix [0 v. 1]: \\n\",confusion_matrix(labels_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tune_params(grid_search, features, labels, params, iters = 80):\n",
    "    \"\"\" given a grid_search and parameters list (if exist) for a specific model,\n",
    "    along with features and labels list,\n",
    "    it tunes the algorithm using grid search and prints out the average evaluation metrics\n",
    "    results (accuracy, percision, recall) after performing the tuning for iter times,\n",
    "    and the best hyperparameters for the model\n",
    "    \"\"\"\n",
    "    acc = []\n",
    "    pre = []\n",
    "    recall = []\n",
    "    for i in range(iters):\n",
    "        features_train, features_test, labels_train, labels_test = \\\n",
    "        train_test_split(features, labels, test_size = 0.3, random_state = i)\n",
    "        grid_search.fit(features_train, labels_train)\n",
    "        predicts = grid_search.predict(features_test)\n",
    "\n",
    "        acc = acc + [accuracy_score(labels_test, predicts)] \n",
    "        pre = pre + [precision_score(labels_test, predicts)]\n",
    "        recall = recall + [recall_score(labels_test, predicts)]\n",
    "    print \"accuracy: {}\".format(np.mean(acc))\n",
    "    print \"precision: {}\".format(np.mean(pre))\n",
    "    print \"recall: {}\".format(np.mean(recall))\n",
    "\n",
    "    best_params = grid_search.best_estimator_.get_params()\n",
    "    for param_name in params.keys():\n",
    "        print(\"%s = %r, \" % (param_name, best_params[param_name]))\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. Logistic Regression\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "lr_clf = LogisticRegression()\n",
    "lr_param = {'tol': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "'C': [0.1, 0.01, 0.001, 0.0001]}\n",
    "# lr_grid_search = GridSearchCV(estimator = lr_clf, param_grid = lr_param)\n",
    "GridSearchCV(estimator = lr_clf, param_grid = lr_param)\n",
    "\n",
    "print(\"Logistic Regression model evaluation\")\n",
    "tune_params(lr_grid_search, features, labels, lr_param) ### <<<---\n",
    "# tune_params(lr_grid_search, new_features, new_labels, lr_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LR may be great for such case study. \n",
    "# The only concern: n(POI) is small \n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf4 = LogisticRegression(C=1e5)\n",
    "clf4.fit(features_train, labels_train)\n",
    "pred = clf4.predict(features_test)\n",
    "print \"Accuracy =\", accuracy_score(labels_test, pred)\n",
    "print \"Precision =\", precision_score(labels_test, pred)\n",
    "print \"Summary\", classification_report(labels_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LR2\n",
    "from sklearn.pipeline import Pipeline\n",
    "clf = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=4, whiten=False)),\n",
    "        ('classifier', LogisticRegression(tol=0.01, C=1e-08, penalty='l2', random_state=42))])\n",
    "\n",
    "clf.fit(features_train, labels_train)\n",
    "print \"Training time:\",(\"{0:.1f}\".format(time()-t0)),\"second(s)\"\n",
    "\n",
    "tpredict = time()\n",
    "predict = clf.predict(features_test)\n",
    "print \"Prediction run time:\",(\"{0:.1f}\".format(time()-tpredict)),\"second(s)\"\n",
    "accuracy = accuracy_score(predict, labels_test)\n",
    "print \"Accuracy =\",(\"{0:.3f}\".format(accuracy)),\"\\n\\nModel:\\n\",clf\n",
    "\n",
    "print \"\\nConfusion Matrix [0 v. 1]: \\n\",confusion_matrix(labels_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# enron_df['poi'].value_counts()\n",
    "\n",
    "enron_df.index.name = \"Name\"\n",
    "\n",
    "enron_df.drop([\"email_address\"], inplace=True,axis=1)\n",
    "\n",
    "#convert columns from objects to float\n",
    "for col in enron_df.columns:\n",
    "    if enron_df[col].dtype == object:\n",
    "        enron_df[col] = enron_df[col].astype(\"float64\")\n",
    "\n",
    "enron_df[] = enron_df.isnull.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "#Transform dictionary into pandas\n",
    "data = pd.DataFrame.from_dict(data_dict, orient = \"index\")\n",
    "\n",
    "#Setting index name of pandas data frame to POI's name\n",
    "data.index.name = \"Name\"\n",
    "\n",
    "#remove irrelevant fields like emails\n",
    "data.drop([\"email_address\"], inplace=True,axis=1)\n",
    "\n",
    "#convert columns from objects to float\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == object:\n",
    "        data[col] = data[col].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 2. SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "clf = SVC(kernel=\"linear\", C = 100.0)\n",
    "clf.fit(features_train, labels_train)\n",
    "print \"Training time:\",(\"{0:.1f}\".format(time()-t0)),\"second(s)\"\n",
    "\n",
    "tpredict = time()\n",
    "predict = clf.predict(features_test)\n",
    "print \"Prediction run time:\",(\"{0:.1f}\".format(time()-tpredict)),\"second(s)\"\n",
    "accuracy = accuracy_score(predict, labels_test)\n",
    "print \"Accuracy =\",(\"{0:.3f}\".format(accuracy)),\"\\n\\nModel:\\n\",clf\n",
    "\n",
    "#print \":: \\nAccuracy =\",(\"{0:.3f}\".format(accuracy)),\"\\nModel: \",clf\n",
    "#, (\"{0:.3f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 3. Decision Tree\n",
    "from sklearn import tree\n",
    "\n",
    "t0= time()\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "print \"Training time:\",(\"{0:.1f}\".format(time()-t0)),\"second(s)\"\n",
    "\n",
    "tpredict = time()\n",
    "predict = clf.predict(features_test, labels_test)\n",
    "print \"Prediction run time:\",(\"{0:.1f}\".format(time()-tpredict)),\"second(s)\"\n",
    "\n",
    "accuracy = clf.score(features_test, labels_test)\n",
    "print \"Accuracy =\",(\"{0:.3f}\".format(accuracy)),\"\\n\\nModel:\\n\",clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. Regressions\n",
    "\n",
    "# dictionary = pickle.load( open(\"../final_project/final_project_dataset_modified.pkl\", \"r\") )\n",
    "\n",
    "### list the features you want to look at--first item in the \n",
    "### list will be the \"target\" feature\n",
    "features_list = [\"bonus\", \"salary\"]\n",
    "data = featureFormat( dictionary, features_list, remove_any_zeroes=True)\n",
    "target, features = targetFeatureSplit( data )\n",
    "\n",
    "### training-testing split needed in regression, just like classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(features, target, test_size=0.5, random_state=42)\n",
    "train_color = \"b\"\n",
    "test_color = \"r\"\n",
    "\n",
    "\n",
    "\n",
    "### Your regression goes here!\n",
    "### Please name it reg, so that the plotting code below picks it up and \n",
    "### plots it correctly. Don't forget to change the test_color above from \"b\" to\n",
    "### \"r\" to differentiate training points from test points.\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(feature_train, target_train)\n",
    "\n",
    "print \"m:\", reg.coef_[0]\n",
    "print \"c:\", reg.intercept_\n",
    "print \"Train Score:\", reg.score(feature_train, target_train)\n",
    "print \"Test Score:\", reg.score(feature_test, target_test)\n",
    "\n",
    "\n",
    "### draw the scatterplot, with color-coded training and testing points\n",
    "import matplotlib.pyplot as plt\n",
    "for feature, target in zip(feature_test, target_test):\n",
    "    plt.scatter( feature, target, color=test_color ) \n",
    "for feature, target in zip(feature_train, target_train):\n",
    "    plt.scatter( feature, target, color=train_color ) \n",
    "\n",
    "### labels for the legend\n",
    "plt.scatter(feature_test[0], target_test[0], color=test_color, label=\"test\")\n",
    "plt.scatter(feature_test[0], target_test[0], color=train_color, label=\"train\")\n",
    "\n",
    "\n",
    "### draw the regression line, once it's coded\n",
    "try:\n",
    "    plt.plot( feature_test, reg.predict(feature_test) )\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "reg.fit(feature_test, target_test)\n",
    "print \"m_woOutlier:\", reg.coef_[0]\n",
    "plt.plot(feature_train, reg.predict(feature_train), color=\"b\") # Outlier?\n",
    "plt.xlabel(features_list[1])\n",
    "plt.ylabel(features_list[0])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\" \n",
    "    This is the code to accompany the Lesson 2 (SVM) mini-project.\n",
    "\n",
    "    Use a SVM to identify emails from the Enron corpus by their authors:    \n",
    "    Sara has label 0\n",
    "    Chris has label 1\n",
    "\"\"\"\n",
    "    \n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################\n",
    "### your code goes here ###\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel=\"linear\", C = 10000.0)\n",
    "clf.fit(features_train, labels_train)\n",
    "predict = clf.predict(features_test)\n",
    "\n",
    "print accuracy_score(predict, labels_test)\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVM - Scaled\n",
    "\n",
    "features_list = ['poi', 'exercised_stock_options','bonus','salary'] \n",
    "# features_list = ['poi', 'exercised_stock_options','bonus','salary','deferred_income','long_term_incentive','restricted_stock'] \n",
    "\n",
    "# Apply standardization to SVM\n",
    "features_trainX = scaler.fit(features_train).transform(features_train)\n",
    "features_testX = scaler.fit(features_test).transform(features_test)\n",
    "\n",
    "C = [10, 100] ### 0.01, 0.1, 1 results were not good\n",
    "gamma_list = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "svm_param = ['rbf', 'sigmoid'] # kernel; rbf the fastest\n",
    "# n_sample = [0.3, 0.35, 0.4, 0.5] # kernel; rbf the fastest\n",
    "\n",
    "print \"C | gamma | svmpar | n_pred | acc | prec | recall \\n\"\n",
    "\n",
    "# a more hands on approach\n",
    "for ccc in C:\n",
    "    for ggg in gamma_list:\n",
    "        for svmpar in svm_param:\n",
    "            # for nnn in n_sample:\n",
    "                # Test Size\n",
    "            features_trainX, features_testX, labels_train, labels_test \\\n",
    "            = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "            clf = SVC(kernel=svmpar, C = ccc, gamma=ggg)\n",
    "            clf.fit(features_trainX, labels_train)\n",
    "            predict = clf.predict(features_testX)\n",
    "            acc = accuracy_score(labels_test, predict)\n",
    "            prec = precision_score(labels_test, predict)\n",
    "            recall = recall_score(labels_test, predict)\n",
    "\n",
    "            print ccc, ggg, svmpar,sum(predict),(\"{0:.3f}\".format(acc)), (\"{0:.3f}\".format(prec)), (\"{0:.3f}\".format(recall)),\"\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
    "\n",
    "max_features=None, max_leaf_nodes=10, min_impurity_split=1e-07,\n",
    "            \n",
    "min_samples_leaf=1, min_samples_split=2,\n",
    "            \n",
    "min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            \n",
    "splitter='best')\n",
    "            \n",
    "Accuracy: 0.81738\tPrecision: 0.38789\tRecall: 0.32350\tF1: 0.35278\tF2: 0.33461\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selecting Best Features via SelectKBest\n",
    "# http://parneetk.github.io/blog/intro-to-sklearn/\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list_n, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "selector = SelectKBest(f_classif, k = 10)\n",
    "selector.fit(features, labels)\n",
    "scores = zip(features_list_n[1:], selector.scores_)\n",
    "sorted_scores = sorted(scores, key = takeSecond, reverse = True)\n",
    "print 'SelectKBest scores: ', sorted_scores\n",
    "\n",
    "kBest_features = POI_label + [(i[0]) for i in sorted_scores[0:10]]\n",
    "print 'KBest', kBest_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parsing data_dict and splitting into features and labels\n",
    "data = featureFormat(data_dict, features_list)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "# creating and fitting the selector using the features and labels\n",
    "k_best = SelectKBest(f_classif, k='all')\n",
    "k_best.fit(features, labels)\n",
    "\n",
    "k_best.scores_\n",
    "\n",
    "# Get the raw p-values for each feature, and transform from p-values into scores\n",
    "#scores = -np.log10(k_best.pvalues_)\n",
    "\n",
    "# Score Plot\n",
    "#plt.bar(features, scores)\n",
    "#plt.bar(range(len(features)), scores)\n",
    "#plt.xticks(range(len(features)), features, rotation='vertical')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Selection:: \n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "k_best = SelectKBest(k=10)\n",
    "k_best.fit(features, labels)\n",
    "scores = k_best.scores_\n",
    "unsorted_pairs = zip(features_list[1:], scores)\n",
    "sorted_pairs = list(reversed(sorted(unsorted_pairs, key=lambda x: x[1])))\n",
    "k_best_features = dict(sorted_pairs[:k])\n",
    "print \"{0} best features: {1}\\n\".format(k, k_best_features.keys())\n",
    "print \"Best\",k_best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca =PCA()\n",
    "pca.fit(features,labels)\n",
    "#print(pca.explained_variance_ratio_)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "import numpy as np\n",
    "\n",
    "# Parsing data_dict and splitting into features and labels\n",
    "data = featureFormat(data_dict, features_list)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "# creating and fitting the selector using the features and labels\n",
    "k_best = SelectKBest(k='all')\n",
    "k_best.fit(features, labels)\n",
    "k_best.scores_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Draw(pred, features, poi, mark_poi=False, name=\"image.png\", f1_name=\"feature 1\", f2_name=\"feature 2\"):\n",
    "    \"\"\" some plotting code designed to help you visualize your clusters \"\"\"\n",
    "\n",
    "    ### plot each cluster with a different color--add more colors for\n",
    "    ### drawing more than five clusters\n",
    "    colors = [\"b\", \"c\", \"k\", \"m\", \"g\"]\n",
    "    for ii, pp in enumerate(pred):\n",
    "        plt.scatter(features[ii][0], features[ii][1], color = colors[pred[ii]])\n",
    "\n",
    "    ### if you like, place red stars over points that are POIs (just for funsies)\n",
    "    if mark_poi:\n",
    "        for ii, pp in enumerate(pred):\n",
    "            if poi[ii]:\n",
    "                plt.scatter(features[ii][0], features[ii][1], color=\"r\", marker=\"*\")\n",
    "    plt.xlabel(f1_name)\n",
    "    plt.ylabel(f2_name)\n",
    "    plt.savefig(name)\n",
    "    plt.scatter(kmeans.cluster_centers_[:,0] ,kmeans.cluster_centers_[:,1], color='pink',\n",
    "               marker=\"x\")  \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ### load in the dict of dicts containing all the data on each person in the dataset\n",
    "# data_dict = pickle.load( open(\"../final_project/final_project_dataset.pkl\", \"r\") )\n",
    "# ### there's an outlier--remove it! \n",
    "# data_dict.pop(\"TOTAL\", 0)\n",
    "\n",
    "\n",
    "### the input features we want to use \n",
    "### can be any key in the person-level dictionary (salary, director_fees, etc.) \n",
    "feature_1 = \"salary\"\n",
    "feature_2 = \"exercised_stock_options\"\n",
    "poi  = \"poi\"\n",
    "features_list = [poi, feature_1, feature_2]\n",
    "data = featureFormat(data_dict, features_list )\n",
    "poi, finance_features = targetFeatureSplit( data )\n",
    "\n",
    "\n",
    "### in the \"clustering with 3 features\" part of the mini-project,\n",
    "### you'll want to change this line to \n",
    "### for f1, f2, _ in finance_features:\n",
    "### (as it's currently written, the line below assumes 2 features)\n",
    "for f1, f2 in finance_features:\n",
    "    plt.scatter( f1, f2 )\n",
    "plt.show()\n",
    "\n",
    "### cluster here; create predictions of the cluster labels\n",
    "### for the data and store them to a list called pred\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=0, max_iter=20, n_init=25)\n",
    "kmeans.fit(finance_features)\n",
    "pred = kmeans.predict(finance_features)\n",
    "\n",
    "print \"Label Points: \\n\",(kmeans.labels_)\n",
    "print\n",
    "print \"Cluster Center Points: \\n\",(kmeans.cluster_centers_)\n",
    "\n",
    "### rename the \"name\" parameter when you change the number of features\n",
    "### so that the figure gets saved to a different file\n",
    "try:\n",
    "    Draw(pred, finance_features, poi, mark_poi=False, name=\"clusters.pdf\", f1_name=feature_1, f2_name=feature_2)\n",
    "except NameError:\n",
    "    print \"no predictions object named pred found, no clusters to plot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# features_list = ['poi', 'salary', 'bonus', 'total_stock_value'] \n",
    "features_list = ['poi', 'salary', 'bonus', 'total_stock_value', 'expenses', 'shared_receipt_with_poi', 'from_poi_to_this_person'] \n",
    "\n",
    "\n",
    "# elif algorithm == 'Adaboost':\n",
    "#     cl = AdaBoostClassifier()\n",
    "#     cl_params = { algorithm + '__n_estimators' : [5, 8, 10, 20, 30, 50, 100],\n",
    "#                   algorithm + '__learning_rate' : [0.025, 0.05, 0.1, 0.5, 1, 2, 4, 6]\n",
    "\n",
    "# Test Size\n",
    "features_train, features_test, labels_train, labels_test \\\n",
    "= train_test_split(features, labels, test_size=0.30, random_state=42)\n",
    "\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)  \n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier()\n",
    "# test_classifier(clf, my_dataset, features_list)\n",
    "\n",
    "#dt = tree.DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'__n_estimators':[5, 8, 10, 20, 30, 50, 100],\n",
    "                '__learning_rate':[0.025, 0.05, 0.1, 0.5, 1, 2, 4, 6]}\n",
    "\n",
    "\n",
    "cv_strata = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
    "grid_search = GridSearchCV(ada, parameters, cv=cv_strata, scoring='f1')\n",
    "\n",
    "grid_search.fit(features, labels)\n",
    "clf = grid_search.best_estimator_\n",
    "\n",
    "from tester import test_classifier\n",
    "\n",
    "print \"Tester Classification\\n\" \n",
    "test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Rescaling\n",
    "\n",
    "import pickle\n",
    "import numpy\n",
    "#import matplotlib.pyplot as plt\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "# ### load in the dict of dicts containing all the data on each person in the dataset\n",
    "# data_dict = pickle.load( open(\"../final_project/final_project_dataset.pkl\", \"r\") )\n",
    "# ### there's an outlier--remove it! \n",
    "# data_dict.pop(\"TOTAL\", 0)\n",
    "\n",
    "# # the features to be used\n",
    "features_list = ['poi', 'salary', 'exercised_stock_options']\n",
    "\n",
    "data = featureFormat(data_dict, features_list)\n",
    "\n",
    "_, salary, stock = zip(*data)\n",
    "\n",
    "# put the features into 2-D numpy arrays\n",
    "salary = numpy.array(salary).reshape((len(salary),1))\n",
    "stock = numpy.array(stock).reshape((len(stock),1))\n",
    "\n",
    "# rescale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "salary = scaler.fit_transform(salary)\n",
    "print '$200,000 becomes {0}'.format(scaler.transform([[200000.]])[0][0])\n",
    "\n",
    "stock = scaler.fit_transform(stock)\n",
    "print '$1,000,000 becomes {0}'.format(scaler.transform([[1000000.]])[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=15,\n",
    "            max_features=None, max_leaf_nodes=40, min_impurity_split=1e-07,\n",
    "            min_samples_leaf=1, min_samples_split=3,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best')\n",
    "\tAccuracy: 0.77238\tPrecision: 0.29070\tRecall: 0.33300\tF1: 0.31042\tF2: 0.32358\n",
    "\n",
    "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=15,\n",
    "            max_features=None, max_leaf_nodes=30, min_impurity_split=1e-07,\n",
    "            min_samples_leaf=1, min_samples_split=5,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='random')\n",
    "\tAccuracy: 0.80515\t**Precision: 0.30476**\tRecall: 0.20800\tF1: 0.24725\tF2: 0.22210\n",
    "    \n",
    "estim = AdaBoostClassifier()\n",
    "for lr, ne in product([0.1, 1, 5, 10], [10, 25, 50, 100]):\n",
    "\tclf = AdaBoostClassifier(learning_rate=lr, n_estimators=ne)\n",
    "\ttest_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Created by DKS 1/26/16 to facilitate comparing different algorithms\n",
    "https://github.com/dksmith01/Enron-Email-Analysis/blob/master/poi_id_testing_all_algorithms.py\n",
    "    \n",
    "def create_classifier_step(algorithm):\n",
    "    cl_params = {}\n",
    "    if algorithm == 'Naive_Bayes':\n",
    "        cl = GaussianNB()\n",
    "    elif algorithm == 'SVC':\n",
    "        cl = SVC()\n",
    "        cl_params = { algorithm + '__kernel' : ['rbf', 'poly'],\n",
    "                      algorithm + '__C' : [1000, 10000, 100000]\n",
    "                    }\n",
    "    elif algorithm == 'Standard_Decision_Tree':\n",
    "        cl = tree.DecisionTreeClassifier()\n",
    "        cl_params = { algorithm + '__min_samples_split' : [30, 40, 50] }\n",
    "    elif algorithm == 'K_Nearest_Neighbors':\n",
    "        cl = KNeighborsClassifier()\n",
    "        cl_params = { algorithm + '__n_neighbors' : [6, 8, 10],\n",
    "                      algorithm + '__weights' : ['uniform']\n",
    "                    }\n",
    "    elif algorithm == 'Adaboost':\n",
    "        cl = AdaBoostClassifier()\n",
    "        cl_params = { algorithm + '__n_estimators' : [5, 8, 10, 20, 30, 50, 100],\n",
    "                      algorithm + '__learning_rate' : [0.025, 0.05, 0.1, 0.5, 1, 2, 4, 6]\n",
    "                    }\n",
    "    elif algorithm == 'Random_Forest':\n",
    "        cl = RandomForestClassifier()\n",
    "        cl_params = { algorithm + '__max_features' : ['sqrt', 'log2'],\n",
    "                      algorithm + '__n_estimators' : [2, 5, 7, 10, 15]}\n",
    "    elif algorithm == 'LDA':\n",
    "        cl = LDA()\n",
    "        cl_params = { algorithm + '__solver' : ['svd', 'lsqr', 'eigen']}\n",
    "return (algorithm, cl), cl_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** DecisionTreeClassifier **\n",
    "\n",
    "    elif algorithm == 'Standard_Decision_Tree':\n",
    "        cl = tree.DecisionTreeClassifier()\n",
    "        cl_params = { algorithm + '__min_samples_split' : [30, 40, 50] }\n",
    "    elif algorithm == 'K_Nearest_Neighbors':\n",
    "        cl = KNeighborsClassifier()\n",
    "        cl_params = { algorithm + '__n_neighbors' : [6, 8, 10],\n",
    "                      algorithm + '__weights' : ['uniform']\n",
    "                    }\n",
    "    elif algorithm == 'Adaboost':\n",
    "        cl = AdaBoostClassifier()\n",
    "        cl_params = { algorithm + '__n_estimators' : [5, 8, 10, 20, 30, 50, 100],\n",
    "                      algorithm + '__learning_rate' : [0.025, 0.05, 0.1, 0.5, 1, 2, 4, 6]\n",
    "                    }\n",
    "    elif algorithm == 'Random_Forest':\n",
    "        cl = RandomForestClassifier()\n",
    "        cl_params = { algorithm + '__max_features' : ['sqrt', 'log2'],\n",
    "                      algorithm + '__n_estimators' : [2, 5, 7, 10, 15]}\n",
    "    elif algorithm == 'LDA':\n",
    "        cl = LDA()\n",
    "        cl_params = { algorithm + '__solver' : ['svd', 'lsqr', 'eigen']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Template \n",
    "\n",
    "\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi','salary'] # You will need to use more features\n",
    "\n",
    "### Task 2: Remove outliers\n",
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "\n",
    "# enron_df['ln_bonus'] = np.log(1+enron_df['bonus'])\n",
    "# enron_df['ln_salary'] = np.log(1+enron_df['salary'])\n",
    "\n",
    "# enron_df['fraction_to_poi'] = \\\n",
    "# enron_df['from_this_person_to_poi']/enron_df['from_messages']\n",
    "\n",
    "# # clean all 'inf' values which we got if the person's from_messages = 0\n",
    "# enron_df.replace('inf', 0.0, inplace=True)\n",
    "# enron_df.replace('NaN', 0.0, inplace=True)\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "# Provided to give you a starting point. Try a variety of classifiers.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "\n",
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "# dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
